{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZoliN/colab/blob/main/blade.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJEFdQ_FgChu",
        "outputId": "e411fd7a-5360-4966-afec-0dc6eefc841d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqsfE7V8DfvS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIKAVeuFGdJ7"
      },
      "outputs": [],
      "source": [
        "!unzip \"/content/drive/MyDrive/Colab Notebooks/zip.zip\" -d /content/\n",
        "%cd /content/zip\n",
        "!mkdir build\n",
        "%cd build\n",
        "!cmake .. -DCMAKE_BUILD_TYPE=Release"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKO7Gs9TazN6"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!wget  http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n",
        "!mkdir pics\n",
        "!unzip DIV2K_train_HR.zip -d pics/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qs-jiTJ9dtk5",
        "outputId": "caef592d-fdc6-4332-e033-c66d1f5761ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pics/DIV2K_train_HR\n"
          ]
        }
      ],
      "source": [
        "%cd /content/pics/DIV2K_train_HR\n",
        "!sh /content/drive/MyDrive/blade/copypics.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGU_PynQMCBJ",
        "outputId": "3a963cb8-0be9-412e-887c-fdbe0b6a8373"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/zip/build\n",
            "[ 10%] \u001b[32mBuilding CXX object CMakeFiles/blade.dir/HashBuckets.cpp.o\u001b[0m\n",
            "[ 20%] \u001b[32m\u001b[1mLinking CXX executable blade\u001b[0m\n",
            "[100%] Built target blade\n"
          ]
        }
      ],
      "source": [
        " %cd /content/zip/build\n",
        "!make -j4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVPCGRqEAB-K"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/drive/MyDrive/Colab Notebooks/2023_5_28_1_35_27.filter\"  /content/zip/filters/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0UONCsDbi04"
      },
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0UXLfCNOFyj",
        "outputId": "d73ab8f3-2f11-4c54-e7d2-3daf93f82b10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/zip/train_images\n"
          ]
        }
      ],
      "source": [
        "%cd /content/zip/train_images\n",
        "!mv *.png ./p/\n",
        "!mv ./p/08.png .\n",
        "!for i in {1..1000}; do cp 08.png \"test$i.png\"; done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWc4SrbPwJyB"
      },
      "outputs": [],
      "source": [
        "%cd /content/zip/\n",
        "!./build/blade\n",
        "!cp -r filters /content/drive/MyDrive/blade/\n",
        "!cp -r result_images /content/drive/MyDrive/blade/\n",
        "!cp temp_images/*.csv /content/drive/MyDrive/blade/\n",
        "while True:pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcweFQIsl_Sb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmzc68Ot5ra9"
      },
      "outputs": [],
      "source": [
        "!zip -r /content/drive/MyDrive/bladearch/src.zip /content/drive/MyDrive/blade/*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "!mkdir build\n",
        "%cd build\n",
        "!cmake /content/drive/MyDrive/superrestf/bladesr -DCMAKE_BUILD_TYPE=Release\n",
        "!pip install python_magic\n",
        "!apt-get install libmagic1"
      ],
      "metadata": {
        "id": "kUKzkXvvV7ZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " %cd /content/build\n",
        "!make -j4"
      ],
      "metadata": {
        "id": "rvKf-9a3WOxs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1488e536-96c1-4211-fee6-ba920a349ea3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/build\n",
            "[ 10%] \u001b[32mBuilding CXX object CMakeFiles/blade.dir/BLADE.cpp.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object CMakeFiles/blade.dir/Utils.cpp.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object CMakeFiles/blade.dir/HashBuckets.cpp.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object CMakeFiles/blade.dir/dctdenoise.cpp.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object CMakeFiles/blade.dir/fastguidedfilter.cpp.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object CMakeFiles/blade.dir/hq_demoblade.cpp.o\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object CMakeFiles/blade.dir/imgbackproc.cpp.o\u001b[0m\n",
            "[ 80%] \u001b[32mBuilding CXX object CMakeFiles/blade.dir/lib_transforms.cpp.o\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object CMakeFiles/blade.dir/main.cpp.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable blade\u001b[0m\n",
            "[100%] Built target blade\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs('/content/anal_images', exist_ok=True)\n",
        "!/content/build/blade\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "\n",
        "def iterate_files(directory):\n",
        "    for file in os.listdir(directory):\n",
        "        yield os.path.join(directory, file)\n",
        "\n",
        "inpath = '/content/anal_images'\n",
        "outpath = '/content/anal_tensors'\n",
        "os.makedirs(outpath, exist_ok=True)\n",
        "# Iterate over the files of the current directory\n",
        "for file in iterate_files(inpath):\n",
        "    filename = os.path.basename(file)\n",
        "    print(filename)\n",
        "    im_input = cv2.imread(file, -1)\n",
        "    print(im_input.shape)\n",
        "\n",
        "    byte_string = tf.io.serialize_tensor(im_input)\n",
        "    # Write the byte string to a file\n",
        "    with tf.io.gfile.GFile(outpath + '/' + filename[:-5] + '.bin', 'wb') as f:\n",
        "        f.write(byte_string.numpy())\n"
      ],
      "metadata": {
        "id": "q_XyDd3LWiJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "scale = 2\n",
        "scalef = float(scale)\n",
        "invscale = 1./scalef\n",
        "\n",
        "img_raw = tf.io.read_file('/content/drive/MyDrive/superrestf/bladesr/test_images/12.png')\n",
        "im_input = tf.image.decode_image(img_raw)\n",
        "im_input = tf.cast(im_input, dtype=tf.float32)/255.0\n",
        "\n",
        "orig_sz = tf.shape(im_input)[0:2]\n",
        "lr_sz = orig_sz // scale\n",
        "full_sz = lr_sz * scale\n",
        "\n",
        "\n",
        "analpath = '/content/anal_tensors'\n",
        "byte_string = []\n",
        "with tf.io.gfile.GFile(analpath + '/' + '12.png' + '.bin', 'rb') as f:\n",
        "    byte_string = f.read()\n",
        "\n",
        "# Deserialize the tensor from the byte string\n",
        "anal_tensor = tf.io.parse_tensor(byte_string, out_type=tf.float32)\n",
        "print(tf.shape(input=anal_tensor))\n",
        "\n",
        "lam1, lam2, c, s = tf.unstack(anal_tensor, axis=-1)\n",
        "\n",
        "Dtr = 3000. * 1.525902E-05 * 0.860704768\n",
        "Dth = 1000. * 1.525902E-05 * 0.860704768 * 1. / Dtr;\n",
        "kDetail = 0.5;\n",
        "kDenoise = 1.55;\n",
        "kStretch = 4.;\n",
        "kShrink = 1.;\n",
        "\n",
        "Dtr=0.0039259493\n",
        "Dth=0.33213648\n",
        "kDetail=0.6002224\n",
        "kDenoise=0.5469237\n",
        "kStretch=2.291745\n",
        "kShrink=2.3721561\n",
        "\n",
        "kDetail=0.09206551\n",
        "kDenoise=0.54780656\n",
        "kStretch=2.5246003\n",
        "kShrink=0.6465685\n",
        "kDetail2=0.4790197\n",
        "kDenoise2=1.0956131\n",
        "\n",
        "\n",
        "A = (lam1 - lam2) / (lam1 + lam2 + 0.0000000001);\n",
        "A = tf.clip_by_value(A, 0.1, 1.0);\n",
        "\n",
        "D = 1. - tf.sqrt(lam1) / Dtr + Dth\n",
        "D = tf.clip_by_value(D, 0.0, 1.0)\n",
        "\n",
        "k1h = kDetail * (kStretch * A +  (1. - A));\n",
        "k2h = kDetail / (kShrink * A +  (1. - A));\n",
        "\n",
        "k1 = ((1.0 - D)*k1h + D*kDenoise);\n",
        "k2 = ((1.0 - D)*k2h + D*kDenoise);\n",
        "k1 *= k1;\n",
        "k2 *= k2;\n",
        "\n",
        "x2 = c;\n",
        "y2 = s;\n",
        "x1 = s;\n",
        "y1 = -c;\n",
        "\n",
        "b11 = k1*x1*x1 + x2*x2*k2;\n",
        "b12 = k1*x1*y1 + x2*y2*k2;\n",
        "b22 = k1*y1*y1 + y2*y2*k2;\n",
        "\n",
        "det = b11*b22 - b12*b12 + 0.0000000001;\n",
        "\n",
        "m11 = b22 / det;\n",
        "m22 = b11 / det;\n",
        "m12 = -b12 / det;\n",
        "\n",
        "kerp = tf.stack((m11, m22, m12), axis = -1)\n",
        "kerp = tf.image.resize(kerp, full_sz, method='bilinear')\n",
        "m11, m22, m12 = tf.split(kerp, 3, axis = -1)\n",
        "\n",
        "\n",
        "######## k2\n",
        "k1h = kDetail2 * (kStretch * A +  (1. - A));\n",
        "k2h = kDetail2 / (kShrink * A +  (1. - A));\n",
        "\n",
        "k1 = ((1.0 - D)*k1h + D*kDenoise2);\n",
        "k2 = ((1.0 - D)*k2h + D*kDenoise2);\n",
        "k1 *= k1;\n",
        "k2 *= k2;\n",
        "\n",
        "x2 = c;\n",
        "y2 = s;\n",
        "x1 = s;\n",
        "y1 = -c;\n",
        "\n",
        "b11 = k1*x1*x1 + x2*x2*k2;\n",
        "b12 = k1*x1*y1 + x2*y2*k2;\n",
        "b22 = k1*y1*y1 + y2*y2*k2;\n",
        "\n",
        "det = b11*b22 - b12*b12 + 0.0000000001;\n",
        "\n",
        "m11_2 = b22 / det;\n",
        "m22_2 = b11 / det;\n",
        "m12_2 = -b12 / det;\n",
        "\n",
        "kerp = tf.stack((m11_2, m22_2, m12_2), axis = -1)\n",
        "kerp = tf.image.resize(kerp, full_sz, method='bilinear')\n",
        "m11_2, m22_2, m12_2 = tf.split(kerp, 3, axis = -1)\n",
        "\n",
        "\n",
        "im_lr = tf.image.resize(im_input, lr_sz, method='area')\n",
        "\n",
        "im_hr = tf.image.resize(im_lr, full_sz, method='nearest')\n",
        "\n",
        "cv2.imwrite('/content/im_hr.png', im_hr.numpy()*255.0)\n",
        "\n",
        "im_hr2 = tf.image.resize(im_lr, full_sz, method='lanczos3')\n",
        "cv2.imwrite('/content/im_hr2.png', im_hr2.numpy()*255.0)\n",
        "\n",
        "\n",
        "paddings = tf.constant([[2 * scale, 2 * scale], [2 * scale, 2 * scale], [0, 0]])\n",
        "# paddings = tf.constant([[2, 2], [2, 2], [0, 0]])\n",
        "im_padded = tf.pad(im_hr, paddings, \"SYMMETRIC\")\n",
        "\n",
        "#tf.convert_to_tensor(value, dtype=None\n",
        "\n",
        "im_dst = tf.fill(tf.shape(im_hr), 0.0)\n",
        "im_w = tf.fill(tf.shape(im_hr), 0.0)\n",
        "\n",
        "\n",
        "print(tf.shape(input=im_dst))\n",
        "print(tf.shape(input=im_padded))\n",
        "\n",
        "\n",
        "# Create two 1D arrays\n",
        "x_coords = np.arange(float(full_sz[0]))\n",
        "y_coords = np.arange(float(full_sz[1]))\n",
        "\n",
        "# Create a 2D NumPy array containing x and y indices\n",
        "indices = np.meshgrid(x_coords, y_coords)\n",
        "\n",
        "srcpos1 = np.stack([indices[0], indices[1]], 2)\n",
        "srcpos1 = (srcpos1 + 0.4995) * invscale\n",
        "srcpos = tf.convert_to_tensor(srcpos1, dtype=tf.float32)\n",
        "srcMidPos = tf.floor(srcpos) + 0.5;\n",
        "\n",
        "ls = 3.\n",
        "pi = 3.14159265\n",
        "for y in range(5):\n",
        "  ys = y * scale\n",
        "  y1 = float(y - 2)\n",
        "  for x in range(5):\n",
        "    xs = x * scale\n",
        "    x1 = float(x - 2)\n",
        "    posk = (srcMidPos + (x1, y1) - srcpos) #* scalef\n",
        "    poskx, posky = tf.split(posk, 2, axis = -1)\n",
        "    #if (x==2 and y==2):\n",
        "    #  print(poskx.numpy()[0:4,0:4])\n",
        "    kwx = tf.where(poskx == 0.0, 1.0, tf.where(poskx > ls, 0.0,  ls * tf.sin(pi * poskx) * tf.sin(pi * poskx / ls) / (pi * pi * poskx * poskx)))\n",
        "    kwy = tf.where(posky == 0.0, 1.0, tf.where(posky > ls, 0.0,  ls * tf.sin(pi * posky) * tf.sin(pi * posky / ls) / (pi * pi * posky * posky)))\n",
        "    kw = kwx * kwy\n",
        "\n",
        "    # kw1 = tf.exp(-0.5 * ((poskx*m11+posky*m12)*poskx+(poskx*m12+posky*m22)*posky) )\n",
        "    # kw2 = tf.exp(-0.5 * ((poskx*m11_2+posky*m12_2)*poskx+(poskx*m12_2+posky*m22_2)*posky) )\n",
        "    # kw = kw1 * 2.0 - kw2 * 1.0\n",
        "    if (x==4 and y==2):\n",
        "      print(kw.numpy()[0:4,0:4])\n",
        "    im_w += kw\n",
        "    im_dst+= kw * im_padded[ys:ys+full_sz[0], xs: xs+full_sz[1]]\n",
        "\n",
        "halfRatio = invscale * 0.5\n",
        "\n",
        "# for y in range(5):\n",
        "#   y1 = float(y - 2)\n",
        "#   for x in range(5):\n",
        "#     x1 = float(x - 2)\n",
        "#     srcposc = srcpos + (x1 * invscale, y1 * invscale)\n",
        "#     comp = tf.where(tf.abs(srcposc - tf.floor(srcposc) - 0.5) < halfRatio, 1.0, 0.0)\n",
        "#     compx, compy = tf.split(comp, 2, axis = -1)\n",
        "#     kw = tf.where(compx * compx == 1.0, tf.exp(-0.5 * ((x1*m11+y1*m12)*x1+(x1*m12+y1*m22)*y1) ), 0.0)\n",
        "#     #if (x==3 and y==2):\n",
        "#     #  print(kw.numpy()[200:204,200:204])\n",
        "#     im_w += kw\n",
        "#     im_dst+= kw * im_padded[y:y+full_sz[0], x: x+full_sz[1]]\n",
        "\n",
        "\n",
        "im_dst = im_dst / (im_w + 0.0000001)\n",
        "\n",
        "cv2.imwrite('/content/out.png', im_dst.numpy()*255.0)\n",
        "\n",
        "cv2.imwrite('/content/test.jpg', A.numpy()*255.0)\n",
        "\n",
        "print(tf.shape(input=D))\n",
        "print('PSNR: ' + str(tf.image.psnr(im_dst, im_input, max_val=1.0).numpy()))\n",
        "print('PSNR upsampl: ' + str(tf.image.psnr(im_hr2, im_input, max_val=1.0).numpy()))"
      ],
      "metadata": {
        "id": "ZDssoEtqQQWh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9330952-940e-4933-9e60-6d5184893db4"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([256 256   4], shape=(3,), dtype=int32)\n",
            "tf.Tensor([512 512   1], shape=(3,), dtype=int32)\n",
            "tf.Tensor([520 520   1], shape=(3,), dtype=int32)\n",
            "[[[ 0.02672247]\n",
            "  [-0.06025564]\n",
            "  [ 0.02672247]\n",
            "  [-0.06025564]]\n",
            "\n",
            " [[ 0.02673517]\n",
            "  [-0.06028426]\n",
            "  [ 0.02673517]\n",
            "  [-0.06028426]]\n",
            "\n",
            " [[ 0.02672247]\n",
            "  [-0.06025564]\n",
            "  [ 0.02672247]\n",
            "  [-0.06025564]]\n",
            "\n",
            " [[ 0.02673517]\n",
            "  [-0.06028426]\n",
            "  [ 0.02673517]\n",
            "  [-0.06028426]]]\n",
            "tf.Tensor([256 256], shape=(2,), dtype=int32)\n",
            "PSNR: 30.040127\n",
            "PSNR upsampl: 30.021414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import skimage\n",
        "import skimage.io\n",
        "import logging\n",
        "from keras.models import load_model\n",
        "from tensorflow.python.ops.math_ops import truediv\n",
        "import tensorflow_probability as tfp\n",
        "#import tensorflow_addons as tfa\n",
        "\n",
        "\n",
        "import superrestf.models2 as models\n",
        "import superrestf.data_pipeline as dp\n",
        "\n",
        "from importlib import reload\n",
        "\n",
        "reload(models)\n",
        "\n",
        "\n",
        "numImgChs = 1\n",
        "\n",
        "logging.basicConfig(format=\"[%(process)d] %(levelname)s %(filename)s:%(lineno)s | %(message)s\")\n",
        "log = logging.getLogger(\"train\")\n",
        "log.setLevel(logging.INFO)\n",
        "\n",
        "def PSNR(im1, im2):\n",
        "  return tf.image.psnr(im1, im2, max_val=1.0)\n",
        "\n",
        "def returnPrediction(target, pred):\n",
        "  return pred\n",
        "\n",
        "def return0(target, pred):\n",
        "  return 0\n",
        "\n",
        "\n",
        "def l2_lossHist(target, prediction):\n",
        "  loss = tf.reduce_mean(input_tensor=tf.square(target-prediction))\n",
        "\n",
        "  percs = np.linspace(1, 100, 64, endpoint=False, dtype=np.float32)\n",
        "  hist1 = tfp.stats.percentile(target, percs, [1,2,3])\n",
        "  hist2 = tfp.stats.percentile(prediction, percs, [1,2,3])\n",
        "  histdiff2 = tf.reduce_mean(input_tensor=tf.square(hist1-hist2))\n",
        "  return loss + histdiff2 * 10.\n",
        "\n",
        "def PSNR_w(target, prediction):\n",
        "  rgb, segmented = tf.split(target, [numImgChs,1], 3)\n",
        "  squares = segmented * tf.square(rgb-prediction)\n",
        "  squares = tf.reshape(squares, [tf.shape(input=squares)[0], -1])\n",
        "  p = (-10/np.log(10))*tf.math.log(tf.reduce_sum(input_tensor=squares, axis=[1])\n",
        "          / tf.reduce_sum(input_tensor=segmented, axis=[1,2,3]))\n",
        "  return p\n",
        "\n",
        "\n",
        "def l2_w(target, prediction):\n",
        "  rgb, segmented = tf.split(target, [numImgChs,1], 3)\n",
        "  squares = segmented * tf.square(rgb-prediction)\n",
        "  l2 = tf.reduce_sum(input_tensor=squares) / tf.reduce_sum(input_tensor=segmented)\n",
        "  return l2\n",
        "\n",
        "params = {}\n",
        "params['net_input_size'] = 256\n",
        "\n",
        "checkpoint_filepath = '/content/checkpoint'\n",
        "data_dir = '/content/filelist.txt'\n",
        "validation_dir = '/content/filelist.txt'\n",
        "#validation_dir = ''\n",
        "output_resolution = [378, 504]\n",
        "output_resolution = [384, 510]\n",
        "# output_resolution = [1512, 2016]\n",
        "fliplr=False\n",
        "flipud=False\n",
        "rotate=False\n",
        "random_crop=False\n",
        "shuffle=False\n",
        "batch_size = 1\n",
        "learning_rate = 1e-2\n",
        "\n",
        "net_input_size = params['net_input_size']\n",
        "\n",
        "train_samples = dp.ImageFilesDataPipeline(\n",
        "    data_dir,\n",
        "    shuffle=shuffle,\n",
        "    net_input_size=params['net_input_size'],\n",
        "    capacity=1,\n",
        "    min_after_dequeue = 4,\n",
        "    batch_size=batch_size,\n",
        "    fliplr=fliplr, flipud=flipud, rotate=rotate,\n",
        "    random_crop=random_crop,\n",
        "    custaugment=False,\n",
        "    exposuremult=False,\n",
        "    output_resolution=output_resolution,\n",
        "    keras = True,\n",
        "    repeat = True).samples\n",
        "\n",
        "validation_samples = None\n",
        "if validation_dir != '':\n",
        "  validation_samples = dp.ImageFilesDataPipeline(\n",
        "      validation_dir,\n",
        "      net_input_size=params['net_input_size'],\n",
        "      capacity=1,\n",
        "      batch_size=1,\n",
        "      fliplr=False,flipud=False, rotate=False,\n",
        "      random_crop=False,\n",
        "      exposuremult=False,\n",
        "      output_resolution=output_resolution,\n",
        "      keras = True,\n",
        "      repeat = False).samples\n",
        "\n",
        "\n",
        "opti=tf.keras.optimizers.Adam(learning_rate, use_ema=False, ema_momentum=0.1, weight_decay=0.001)\n",
        "#opti=tfa.optimizers.MovingAverage(opti, 0.99)\n",
        "model = models.SRBlade(params)\n",
        "#model = models.HDRNet(params)\n",
        "\n",
        "#model.run_eagerly = False\n",
        "#model = load_model('/content/hdrnet/train/out', compile=False)\n",
        "try:\n",
        "  model.load_weights(checkpoint_filepath)\n",
        "except:\n",
        "  print(\"Couldn't load weights from \",checkpoint_filepath)\n",
        "\n",
        "model.compile(optimizer=opti, loss=['mse', returnPrediction], metrics={'output_1':PSNR},\n",
        "  run_eagerly=False)\n",
        "# model.compile(optimizer=opti, loss=[l2_w, returnPrediction], metrics={'output_1':PSNR_w, 'output_2':return0},\n",
        "# run_eagerly=False)\n",
        "\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "#model_checkpoint_callback = tfa.callbacks.AverageModelCheckpoint(\n",
        "  update_weights=True,\n",
        "  filepath=checkpoint_filepath,\n",
        "  save_weights_only=True,\n",
        "  #monitor= ('val_' if validation_dir != '' else '') + 'output_1_PSNR',\n",
        "  monitor= 'output_1_PSNR',\n",
        "  mode='max',\n",
        "  verbose=1,\n",
        "  save_freq = 'epoch',\n",
        "  save_best_only=True)\n",
        "\n",
        "\n",
        "\n",
        "history = model.fit(train_samples, epochs=50, steps_per_epoch = 300, callbacks=[model_checkpoint_callback],\n",
        "  validation_data = validation_samples, validation_freq = 1, verbose = 'auto')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wIShtZgraOMy",
        "outputId": "e2e3376a-8382-4456-c566-e413eab0ddd7"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n",
            "Tensor(\"strided_slice_1:0\", shape=(), dtype=string)\n",
            "Tensor(\"strided_slice_2:0\", shape=(), dtype=string)\n",
            "Tensor(\"Shape:0\", shape=(3,), dtype=int32)\n",
            "Tensor(\"Shape_1:0\", shape=(3,), dtype=int32)\n",
            "Tensor(\"strided_slice_1:0\", shape=(), dtype=string)\n",
            "Tensor(\"strided_slice_2:0\", shape=(), dtype=string)\n",
            "Tensor(\"Shape:0\", shape=(3,), dtype=int32)\n",
            "Tensor(\"Shape_1:0\", shape=(3,), dtype=int32)\n",
            "Couldn't load weights from  /content/checkpoint\n",
            "Epoch 1/50\n",
            "Tensor(\"sr_blade_23/Shape_3:0\", shape=(4,), dtype=int32)\n",
            "Tensor(\"sr_blade_23/Shape_4:0\", shape=(4,), dtype=int32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['sr_blade_23/kStretch2:0', 'sr_blade_23/kShrink2:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['sr_blade_23/kStretch2:0', 'sr_blade_23/kShrink2:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"sr_blade_23/Shape_3:0\", shape=(4,), dtype=int32)\n",
            "Tensor(\"sr_blade_23/Shape_4:0\", shape=(4,), dtype=int32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['sr_blade_23/kStretch2:0', 'sr_blade_23/kShrink2:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['sr_blade_23/kStretch2:0', 'sr_blade_23/kShrink2:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300/300 [==============================] - ETA: 0s - loss: 0.0013 - PSNR: 28.8103Tensor(\"sr_blade_23/Shape_3:0\", shape=(4,), dtype=int32)\n",
            "Tensor(\"sr_blade_23/Shape_4:0\", shape=(4,), dtype=int32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with output_1_PSNR available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r300/300 [==============================] - 96s 277ms/step - loss: 0.0013 - PSNR: 28.8103 - val_loss: 0.0013 - val_PSNR: 28.9898\n",
            "Epoch 2/50\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0013 - PSNR: 29.0084"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with output_1_PSNR available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r300/300 [==============================] - 81s 269ms/step - loss: 0.0013 - PSNR: 29.0084 - val_loss: 0.0013 - val_PSNR: 29.0206\n",
            "Epoch 3/50\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0013 - PSNR: 29.0210"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with output_1_PSNR available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r300/300 [==============================] - 81s 268ms/step - loss: 0.0013 - PSNR: 29.0210 - val_loss: 0.0013 - val_PSNR: 29.0211\n",
            "Epoch 4/50\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0013 - PSNR: 29.0206"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with output_1_PSNR available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r300/300 [==============================] - 81s 269ms/step - loss: 0.0013 - PSNR: 29.0206 - val_loss: 0.0013 - val_PSNR: 29.0207\n",
            "Epoch 5/50\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0013 - PSNR: 29.0196"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with output_1_PSNR available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r300/300 [==============================] - 80s 266ms/step - loss: 0.0013 - PSNR: 29.0196 - val_loss: 0.0013 - val_PSNR: 29.0210\n",
            "Epoch 6/50\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0013 - PSNR: 29.0209"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with output_1_PSNR available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r300/300 [==============================] - 80s 267ms/step - loss: 0.0013 - PSNR: 29.0209 - val_loss: 0.0013 - val_PSNR: 29.0206\n",
            "Epoch 7/50\n",
            "199/300 [==================>...........] - ETA: 26s - loss: 0.0013 - PSNR: 29.0209"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-74d534d49449>\u001b[0m in \u001b[0;36m<cell line: 146>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m history = model.fit(train_samples, epochs=50, steps_per_epoch = 300, callbacks=[model_checkpoint_callback],\n\u001b[0m\u001b[1;32m    147\u001b[0m   validation_data = validation_samples, validation_freq = 1, verbose = 'auto')\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.Dtr)\n",
        "print(model.Dth)\n",
        "\n",
        "print(model.kDetail)\n",
        "print(model.kDenoise)\n",
        "print(model.kStretch)\n",
        "print(model.kShrink)\n",
        "\n",
        "print(model.kDetail2)\n",
        "print(model.kDenoise2)\n",
        "print(model.kStretch2)\n",
        "print(model.kShrink2)\n",
        "\n",
        "print(3000. * 1.525902E-05 * 0.860704768)\n",
        "print(100. * 1.525902E-05 * 0.860704768 / (3000. * 1.525902E-05 * 0.860704768))"
      ],
      "metadata": {
        "id": "xu3ZRJ04VY2a",
        "outputId": "6ef8044d-b325-4965-b958-d4f49df2e734",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'sr_blade_23/Dtr:0' shape=() dtype=float32, numpy=-0.058685083>\n",
            "<tf.Variable 'sr_blade_23/Dth:0' shape=() dtype=float32, numpy=0.26958576>\n",
            "<tf.Variable 'sr_blade_23/kDetail:0' shape=() dtype=float32, numpy=0.17954803>\n",
            "<tf.Variable 'sr_blade_23/kDenoise:0' shape=() dtype=float32, numpy=0.37570655>\n",
            "<tf.Variable 'sr_blade_23/kStretch:0' shape=() dtype=float32, numpy=3.8093314>\n",
            "<tf.Variable 'sr_blade_23/kShrink:0' shape=() dtype=float32, numpy=0.91588616>\n",
            "<tf.Variable 'sr_blade_23/kDetail2:0' shape=() dtype=float32, numpy=0.6014661>\n",
            "<tf.Variable 'sr_blade_23/kDenoise2:0' shape=() dtype=float32, numpy=0.5032399>\n",
            "<tf.Variable 'sr_blade_23/kStretch2:0' shape=() dtype=float32, numpy=4.0>\n",
            "<tf.Variable 'sr_blade_23/kShrink2:0' shape=() dtype=float32, numpy=1.0>\n",
            "0.039400533807022076\n",
            "0.03333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ln -s /content/drive/MyDrive/superrestf/bladesr/test_images /content/input\n",
        "%cd /content/drive/MyDrive/superrestf/bin\n",
        "!python train2.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWdloDf7Gova",
        "outputId": "3c1c8ce8-e65d-4241-feb3-db6637429785"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}