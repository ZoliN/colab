{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZoliN/colab/blob/main/blade.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJEFdQ_FgChu",
        "outputId": "3b7f296f-cb6a-4271-fc88-160d263d5f94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqsfE7V8DfvS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIKAVeuFGdJ7"
      },
      "outputs": [],
      "source": [
        "!unzip \"/content/drive/MyDrive/Colab Notebooks/zip.zip\" -d /content/\n",
        "%cd /content/zip\n",
        "!mkdir build\n",
        "%cd build\n",
        "!cmake .. -DCMAKE_BUILD_TYPE=Release"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKO7Gs9TazN6"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!wget  http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n",
        "!mkdir pics\n",
        "!unzip DIV2K_train_HR.zip -d pics/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qs-jiTJ9dtk5",
        "outputId": "caef592d-fdc6-4332-e033-c66d1f5761ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pics/DIV2K_train_HR\n"
          ]
        }
      ],
      "source": [
        "%cd /content/pics/DIV2K_train_HR\n",
        "!sh /content/drive/MyDrive/blade/copypics.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGU_PynQMCBJ"
      },
      "outputs": [],
      "source": [
        " %cd /content/zip/build\n",
        "!make -j4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVPCGRqEAB-K"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/drive/MyDrive/Colab Notebooks/2023_5_28_1_35_27.filter\"  /content/zip/filters/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0UONCsDbi04"
      },
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0UXLfCNOFyj",
        "outputId": "d73ab8f3-2f11-4c54-e7d2-3daf93f82b10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/zip/train_images\n"
          ]
        }
      ],
      "source": [
        "%cd /content/zip/train_images\n",
        "!mv *.png ./p/\n",
        "!mv ./p/08.png .\n",
        "!for i in {1..1000}; do cp 08.png \"test$i.png\"; done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWc4SrbPwJyB"
      },
      "outputs": [],
      "source": [
        "%cd /content/zip/\n",
        "!./build/blade\n",
        "!cp -r filters /content/drive/MyDrive/blade/\n",
        "!cp -r result_images /content/drive/MyDrive/blade/\n",
        "!cp temp_images/*.csv /content/drive/MyDrive/blade/\n",
        "while True:pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vcweFQIsl_Sb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43f4a25a-86e7-4276-8420-e29fea323dd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/temp_images’: File exists\n",
            "mkdir: cannot create directory ‘/content/result_images’: File exists\n",
            "mkdir: cannot create directory ‘/content/filters’: File exists\n",
            "mkdir: cannot create directory ‘/content/test_images’: File exists\n",
            "/content\n",
            "0\n",
            "[1;\n",
            " -2;\n",
            " 1]\n",
            "[1;\n",
            " -2;\n",
            " 1]\n",
            "\n",
            "test process start \n",
            "image found: /content/drive/MyDrive/superrestf/bladesr/test_images/01.png\n",
            "image found: /content/drive/MyDrive/superrestf/bladesr/test_images/02.png\n",
            "image found: /content/drive/MyDrive/superrestf/bladesr/test_images/03.png\n",
            "image found: /content/drive/MyDrive/superrestf/bladesr/test_images/04.png\n",
            "image found: /content/drive/MyDrive/superrestf/bladesr/test_images/05.png\n",
            "image found: /content/drive/MyDrive/superrestf/bladesr/test_images/06.png\n",
            "image found: /content/drive/MyDrive/superrestf/bladesr/test_images/07.png\n",
            "image found: /content/drive/MyDrive/superrestf/bladesr/test_images/08.png\n",
            "image found: /content/drive/MyDrive/superrestf/bladesr/test_images/09.png\n",
            "image found: /content/drive/MyDrive/superrestf/bladesr/test_images/10.png\n",
            "image found: /content/drive/MyDrive/superrestf/bladesr/test_images/11.png\n",
            "image found: /content/drive/MyDrive/superrestf/bladesr/test_images/12.png\n",
            "256\n",
            "256\n",
            "128\n",
            "PSNR 01.png Level 0 : 20.2063\n",
            "PSNR 01.png dct : 9.05124\n",
            "256\n",
            "256\n",
            "128\n",
            "PSNR 02.png Level 0 : 20.7136\n",
            "PSNR 02.png dct : 9.23312\n",
            "256\n",
            "256\n",
            "128\n",
            "PSNR 03.png Level 0 : 20.5219\n",
            "PSNR 03.png dct : 10.0222\n",
            "256\n",
            "256\n",
            "128\n",
            "PSNR 04.png Level 0 : 19.2772\n",
            "PSNR 04.png dct : 8.08371\n",
            "256\n",
            "256\n",
            "128\n",
            "PSNR 05.png Level 0 : 19.6974\n",
            "PSNR 05.png dct : 8.68695\n",
            "256\n",
            "256\n",
            "128\n",
            "PSNR 06.png Level 0 : 21.844\n",
            "PSNR 06.png dct : 9.29986\n",
            "256\n",
            "256\n",
            "128\n",
            "PSNR 07.png Level 0 : 20.5783\n",
            "PSNR 07.png dct : 7.90349\n",
            "512\n",
            "512\n",
            "256\n",
            "PSNR 08.png Level 0 : 23.7896\n",
            "PSNR 08.png dct : 9.86738\n",
            "512\n",
            "512\n",
            "256\n",
            "PSNR 09.png Level 0 : 20.838\n",
            "PSNR 09.png dct : 9.12104\n",
            "512\n",
            "512\n",
            "256\n",
            "PSNR 10.png Level 0 : 23.2165\n",
            "PSNR 10.png dct : 10.3338\n",
            "512\n",
            "512\n",
            "256\n",
            "PSNR 11.png Level 0 : 22.4371\n",
            "PSNR 11.png dct : 10.056\n",
            "512\n",
            "512\n",
            "256\n",
            "PSNR 12.png Level 0 : 23.1753\n",
            "PSNR 12.png dct : 10.1931\n",
            "test process done \n"
          ]
        }
      ],
      "source": [
        "!mkdir /content/temp_images\n",
        "!mkdir /content/result_images\n",
        "!mkdir /content/filters\n",
        "!mkdir /content/test_images\n",
        "%cd /content/\n",
        "!/content/build/blade\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!du -h /content/drive/MyDrive/superrestf/bladesr/temp_images/*"
      ],
      "metadata": {
        "id": "dalu1XD_GHLL",
        "outputId": "c005a043-9b8b-4f65-c944-483a2a49ea6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "du: cannot access '/content/drive/MyDrive/superrestf/bladesr/temp_images/*': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmzc68Ot5ra9"
      },
      "outputs": [],
      "source": [
        "!zip -r /content/drive/MyDrive/bladearch/src.zip /content/drive/MyDrive/blade/*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "!mkdir build\n",
        "%cd build\n",
        "!cmake /content/drive/MyDrive/superrestf/bladesr -DCMAKE_BUILD_TYPE=Release\n",
        "!pip install python_magic\n",
        "!apt-get install libmagic1"
      ],
      "metadata": {
        "id": "kUKzkXvvV7ZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " %cd /content/build\n",
        "!make -j4"
      ],
      "metadata": {
        "id": "rvKf-9a3WOxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs('/content/anal_images', exist_ok=True)\n",
        "!/content/build/blade\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def iterate_files(directory):\n",
        "    for file in os.listdir(directory):\n",
        "        yield os.path.join(directory, file)\n",
        "\n",
        "inpath = '/content/anal_images'\n",
        "outpath = '/content/anal_tensors'\n",
        "os.makedirs(outpath, exist_ok=True)\n",
        "# Iterate over the files of the current directory\n",
        "for file in iterate_files(inpath):\n",
        "    filename = os.path.basename(file)\n",
        "    print(filename)\n",
        "    im_input = cv2.imread(file, -1)\n",
        "    print(im_input.shape)\n",
        "    if filename == '12.png.tiff':\n",
        "      np.savetxt('/content/c2.txt', im_input[:,:,3])\n",
        "\n",
        "    byte_string = tf.io.serialize_tensor(im_input)\n",
        "    # Write the byte string to a file\n",
        "    with tf.io.gfile.GFile(outpath + '/' + filename[:-5] + '.bin', 'wb') as f:\n",
        "        f.write(byte_string.numpy())\n"
      ],
      "metadata": {
        "id": "q_XyDd3LWiJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "from importlib import reload\n",
        "import superrestf.models2 as models\n",
        "from importlib import reload\n",
        "reload(models)\n",
        "\n",
        "scale = 2\n",
        "scalef = float(scale)\n",
        "invscale = 1./scalef\n",
        "\n",
        "img_raw = tf.io.read_file('/content/drive/MyDrive/superrestf/bladesr/test_images/12.png')\n",
        "im_input = tf.image.decode_image(img_raw)\n",
        "im_input = tf.cast(im_input, dtype=tf.float32)/255.0\n",
        "\n",
        "# img_raw = tf.io.read_file('/content/pic12.png')\n",
        "# im_input2 = tf.image.decode_image(img_raw, channels=1)\n",
        "# im_input2 = tf.cast(im_input2, dtype=tf.float32)/255.0\n",
        "# print('PSNR: ' + str(tf.image.psnr(im_input2[8:512-8,8:512-8,:], im_input[8:512-8,8:512-8,:], max_val=1.0).numpy()))\n",
        "\n",
        "orig_sz = tf.shape(im_input)[0:2]\n",
        "lr_sz = orig_sz // scale\n",
        "full_sz = lr_sz * scale\n",
        "\n",
        "\n",
        "analpath = '/content/anal_tensors'\n",
        "byte_string = []\n",
        "with tf.io.gfile.GFile(analpath + '/' + '12.png' + '.bin', 'rb') as f:\n",
        "    byte_string = f.read()\n",
        "\n",
        "# Deserialize the tensor from the byte string\n",
        "anal_tensor = tf.io.parse_tensor(byte_string, out_type=tf.float32)\n",
        "print(tf.shape(input=anal_tensor))\n",
        "\n",
        "lam1, lam2, c, s = tf.unstack(anal_tensor, axis=-1)\n",
        "# np.savetxt('/content/c.txt', c.numpy())\n",
        "# np.savetxt('/content/lam1.txt', lam1.numpy())\n",
        "# np.savetxt('/content/lam2.txt', lam2.numpy())\n",
        "Dtr = 3000. * 1.525902E-05 * 0.860704768\n",
        "Dth = 1000. * 1.525902E-05 * 0.860704768 * 1. / Dtr;\n",
        "kDetail = 0.5;\n",
        "kDenoise = 1.55;\n",
        "kStretch = 4.;\n",
        "kShrink = 1.;\n",
        "\n",
        "Dtr=0.0039259493\n",
        "Dth=0.33213648\n",
        "kDetail=0.6002224\n",
        "kDenoise=0.5469237\n",
        "kStretch=2.291745\n",
        "kShrink=2.3721561\n",
        "\n",
        "Dtr=0.48\n",
        "Dth=0.801\n",
        "kDetail=0.1388774\n",
        "kDenoise=0.272592\n",
        "kStretch=3.6042476\n",
        "kShrink=0.590034\n",
        "\n",
        "\n",
        "\n",
        "A = (lam1 - lam2) / (lam1 + lam2 + 0.0000000001);\n",
        "A = tf.clip_by_value(A, 0.1, 1.0);\n",
        "\n",
        "D = 1. - tf.sqrt(lam1) / Dtr + Dth\n",
        "D = tf.clip_by_value(D, 0.0, 1.0)\n",
        "\n",
        "k1h = kDetail * (kStretch * A +  (1. - A));\n",
        "k2h = kDetail / (kShrink * A +  (1. - A));\n",
        "\n",
        "k1 = ((1.0 - D)*k1h + D*kDenoise);\n",
        "k2 = ((1.0 - D)*k2h + D*kDenoise);\n",
        "k1 *= k1;\n",
        "k2 *= k2;\n",
        "\n",
        "x2 = c;\n",
        "y2 = s;\n",
        "x1 = s;\n",
        "y1 = -c;\n",
        "\n",
        "b11 = k1*x1*x1 + x2*x2*k2;\n",
        "b12 = k1*x1*y1 + x2*y2*k2;\n",
        "b22 = k1*y1*y1 + y2*y2*k2;\n",
        "\n",
        "det = b11*b22 - b12*b12 + 0.0000000001;\n",
        "\n",
        "m11 = b22 / det;\n",
        "m22 = b11 / det;\n",
        "m12 = -b12 / det;\n",
        "\n",
        "kerp = tf.stack((m11, m22, m12), axis = -1)\n",
        "kerp = tf.image.resize(kerp, full_sz, method='bilinear')\n",
        "m11, m22, m12 = tf.split(kerp, 3, axis = -1)\n",
        "\n",
        "#np.savetxt('/content/s.txt', s.numpy())\n",
        "kerp = tf.stack((s, c, A), axis = -1)\n",
        "kerp = tf.image.resize(kerp, full_sz, method='area')\n",
        "cos, sin, Coh = tf.split(kerp, 3, axis = -1)\n",
        "\n",
        "######## k2\n",
        "# k1h = kDetail2 * (kStretch * A +  (1. - A));\n",
        "# k2h = kDetail2 / (kShrink * A +  (1. - A));\n",
        "\n",
        "# k1 = ((1.0 - D)*k1h + D*kDenoise2);\n",
        "# k2 = ((1.0 - D)*k2h + D*kDenoise2);\n",
        "# k1 *= k1;\n",
        "# k2 *= k2;\n",
        "\n",
        "# x2 = c;\n",
        "# y2 = s;\n",
        "# x1 = s;\n",
        "# y1 = -c;\n",
        "\n",
        "# b11 = k1*x1*x1 + x2*x2*k2;\n",
        "# b12 = k1*x1*y1 + x2*y2*k2;\n",
        "# b22 = k1*y1*y1 + y2*y2*k2;\n",
        "\n",
        "# det = b11*b22 - b12*b12 + 0.0000000001;\n",
        "\n",
        "# m11_2 = b22 / det;\n",
        "# m22_2 = b11 / det;\n",
        "# m12_2 = -b12 / det;\n",
        "\n",
        "# kerp = tf.stack((m11_2, m22_2, m12_2), axis = -1)\n",
        "# kerp = tf.image.resize(kerp, full_sz, method='bilinear')\n",
        "# m11_2, m22_2, m12_2 = tf.split(kerp, 3, axis = -1)\n",
        "\n",
        "\n",
        "im_lr = tf.image.resize(im_input, lr_sz, method='area')\n",
        "\n",
        "im_hr = tf.image.resize(im_lr, full_sz, method='nearest')\n",
        "\n",
        "\n",
        "\n",
        "checkpoint_filepath = '/content/checkpoint'\n",
        "params = {}\n",
        "params['net_input_size'] = 512\n",
        "model = models.SRBlade(params)\n",
        "try:\n",
        "  model.load_weights(checkpoint_filepath)\n",
        "except:\n",
        "  print(\"Couldn't load weights from \",checkpoint_filepath)\n",
        "\n",
        "model.params['net_input_size'] = tf.Variable(initial_value = 512, trainable=False, name= 'params_net_input_size')\n",
        "\n",
        "model.compile(loss=['mse', returnPrediction], metrics={'output_1':PSNR},\n",
        "  run_eagerly=True)\n",
        "\n",
        "\n",
        "s, c, a, z = tf.unstack(anal_tensor, axis=-1)\n",
        "#a = tf.fill(tf.shape(a), 0.)\n",
        "anal_tensor = tf.stack( (s, c, a, z), 2)\n",
        "outimg = model( {'image_input' : tf.expand_dims(im_lr,0), 'anal_input' : tf.expand_dims(anal_tensor,0)})\n",
        "print(model.trainable_variables)\n",
        "\n",
        "print('PSNR mmodel: ' + str(tf.image.psnr(tf.squeeze(outimg,0), im_input, max_val=1.0).numpy()))\n",
        "cv2.imwrite('/content/outm.png', tf.squeeze(outimg,0).numpy()*255.0)\n",
        "\n",
        "\n",
        "cv2.imwrite('/content/im_lr.png', im_lr.numpy()*255.0)\n",
        "cv2.imwrite('/content/im_hr.png', im_hr.numpy()*255.0)\n",
        "\n",
        "im_hr2 = tf.image.resize(im_lr, full_sz, method='lanczos3')\n",
        "cv2.imwrite('/content/im_hr2.png', im_hr2.numpy()*255.0)\n",
        "\n",
        "\n",
        "paddings = tf.constant([[2 * scale, 2 * scale], [2 * scale, 2 * scale], [0, 0]])\n",
        "# paddings = tf.constant([[2, 2], [2, 2], [0, 0]])\n",
        "im_padded = tf.pad(im_hr, paddings, \"SYMMETRIC\")\n",
        "\n",
        "#tf.convert_to_tensor(value, dtype=None\n",
        "im_dst = tf.fill(tf.concat( full_sz, tf.shape(im_lr)[2]), 0.0)\n",
        "\n",
        "im_dst = tf.fill(tf.shape(im_hr), 0.0)\n",
        "im_w = tf.fill(tf.shape(im_hr), 0.0)\n",
        "\n",
        "\n",
        "print(tf.shape(input=im_dst))\n",
        "print(tf.shape(input=im_padded))\n",
        "\n",
        "\n",
        "# Create two 1D arrays\n",
        "x_coords = np.arange(float(full_sz[0]))\n",
        "y_coords = np.arange(float(full_sz[1]))\n",
        "\n",
        "# Create a 2D NumPy array containing x and y indices\n",
        "indices = np.meshgrid(x_coords, y_coords)\n",
        "\n",
        "srcpos1 = np.stack([indices[0], indices[1]], 2)\n",
        "srcpos1 = (srcpos1 + 0.4995) * invscale\n",
        "srcpos = tf.convert_to_tensor(srcpos1, dtype=tf.float32)\n",
        "srcMidPos = tf.floor(srcpos) + 0.5;\n",
        "\n",
        "ls = 1.\n",
        "xt = 0.5\n",
        "pi = 3.14159265\n",
        "for y in range(5):\n",
        "  ys = y * scale\n",
        "  y1 = float(y - 2)\n",
        "  for x in range(5):\n",
        "    xs = x * scale\n",
        "    x1 = float(x - 2)\n",
        "    posk = (srcMidPos + (x1, y1) - srcpos) #* scalef\n",
        "    poskx, posky = tf.split(posk, 2, axis = -1)\n",
        "    poskxt = (cos * poskx - sin * posky) * xt\n",
        "    poskyt = sin * poskx + cos * posky\n",
        "    poskx = poskxt\n",
        "    posky = poskyt\n",
        "    #if (x==2 and y==2):\n",
        "    #  print(poskx.numpy()[0:4,0:4])\n",
        "    kwx = tf.where(poskx == 0.0, 1.0, ls * tf.sin(pi * poskx) * tf.sin(pi * poskx / ls) / (pi * pi * poskx * poskx))\n",
        "    kwy = tf.where(posky == 0.0, 1.0,ls * tf.sin(pi * posky) * tf.sin(pi * posky / ls) / (pi * pi * posky * posky))\n",
        "    kw = kwx * kwy\n",
        "\n",
        "    #kw = tf.exp(-0.5 * ((poskx*m11+posky*m12)*poskx+(poskx*m12+posky*m22)*posky) )\n",
        "    # kw2 = tf.exp(-0.5 * ((poskx*m11_2+posky*m12_2)*poskx+(poskx*m12_2+posky*m22_2)*posky) )\n",
        "    # kw = kw1 * 2.0 - kw2 * 1.0\n",
        "    #if (x==4 and y==2):\n",
        "    #  print(kw.numpy()[0:4,0:4])\n",
        "    im_w += kw\n",
        "    im_dst+= kw * im_padded[ys:ys+full_sz[0], xs: xs+full_sz[1]]\n",
        "\n",
        "halfRatio = invscale * 0.5\n",
        "\n",
        "# for y in range(5):\n",
        "#   y1 = float(y - 2)\n",
        "#   for x in range(5):\n",
        "#     x1 = float(x - 2)\n",
        "#     srcposc = srcpos + (x1 * invscale, y1 * invscale)\n",
        "#     comp = tf.where(tf.abs(srcposc - tf.floor(srcposc) - 0.5) < halfRatio, 1.0, 0.0)\n",
        "#     compx, compy = tf.split(comp, 2, axis = -1)\n",
        "#     kw = tf.where(compx * compx == 1.0, tf.exp(-0.5 * ((x1*m11+y1*m12)*x1+(x1*m12+y1*m22)*y1) ), 0.0)\n",
        "#     #if (x==3 and y==2):\n",
        "#     #  print(kw.numpy()[200:204,200:204])\n",
        "#     im_w += kw\n",
        "#     im_dst+= kw * im_padded[y:y+full_sz[0], x: x+full_sz[1]]\n",
        "\n",
        "\n",
        "im_dst = im_dst / (im_w + 0.0000001)\n",
        "\n",
        "cv2.imwrite('/content/out.png', im_dst.numpy()*255.0)\n",
        "\n",
        "cv2.imwrite('/content/test.jpg', A.numpy()*255.0)\n",
        "\n",
        "print(tf.shape(input=D))\n",
        "print('PSNR: ' + str(tf.image.psnr(im_dst, im_input, max_val=1.0).numpy()))\n",
        "print('PSNR upsampl: ' + str(tf.image.psnr(im_hr2, im_input, max_val=1.0).numpy()))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZDssoEtqQQWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm /content/input/DIV2K_train_HR\n",
        "!rm /content/input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ykio78zrkina",
        "outputId": "0d0df43a-62a9-4e1a-925a-19e3c6f5d833"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/input/DIV2K_train_HR': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm /content/input/DIV2K_train_HR\n",
        "!rm /content/input\n",
        "!ln -sf /content/drive/MyDrive/superrestf/bladesr/test_images /content/input\n",
        "#!ln -sf /content/pics/DIV2K_train_HR /content/input\n",
        "#!cp /content/drive/MyDrive/superrestf/bladesr/test_images/* /content/input/\n",
        "!rm /content/checkpoint*\n",
        "%cd /content/drive/MyDrive/\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import skimage\n",
        "import skimage.io\n",
        "import logging\n",
        "from keras.models import load_model\n",
        "from tensorflow.python.ops.math_ops import truediv\n",
        "import tensorflow_probability as tfp\n",
        "#import tensorflow_addons as tfa\n",
        "\n",
        "\n",
        "import superrestf.models2 as models\n",
        "import superrestf.data_pipeline as dp\n",
        "\n",
        "from importlib import reload\n",
        "\n",
        "reload(models)\n",
        "reload(dp)\n",
        "\n",
        "\n",
        "numImgChs = 1\n",
        "\n",
        "logging.basicConfig(format=\"[%(process)d] %(levelname)s %(filename)s:%(lineno)s | %(message)s\")\n",
        "log = logging.getLogger(\"train\")\n",
        "log.setLevel(logging.INFO)\n",
        "\n",
        "def PSNR(im1, im2):\n",
        "  return tf.image.psnr(im1, im2, max_val=1.0)\n",
        "\n",
        "def returnPrediction(target, pred):\n",
        "  return pred\n",
        "\n",
        "def return0(target, pred):\n",
        "  return 0\n",
        "\n",
        "\n",
        "def l2_lossHist(target, prediction):\n",
        "  loss = tf.reduce_mean(input_tensor=tf.square(target-prediction))\n",
        "\n",
        "  percs = np.linspace(1, 100, 64, endpoint=False, dtype=np.float32)\n",
        "  hist1 = tfp.stats.percentile(target, percs, [1,2,3])\n",
        "  hist2 = tfp.stats.percentile(prediction, percs, [1,2,3])\n",
        "  histdiff2 = tf.reduce_mean(input_tensor=tf.square(hist1-hist2))\n",
        "  return loss + histdiff2 * 10.\n",
        "\n",
        "def PSNR_w(target, prediction):\n",
        "  rgb, segmented = tf.split(target, [numImgChs,1], 3)\n",
        "  squares = segmented * tf.square(rgb-prediction)\n",
        "  squares = tf.reshape(squares, [tf.shape(input=squares)[0], -1])\n",
        "  p = (-10/np.log(10))*tf.math.log(tf.reduce_sum(input_tensor=squares, axis=[1])\n",
        "          / tf.reduce_sum(input_tensor=segmented, axis=[1,2,3]))\n",
        "  return p\n",
        "\n",
        "\n",
        "def l2_w(target, prediction):\n",
        "  rgb, segmented = tf.split(target, [numImgChs,1], 3)\n",
        "  squares = segmented * tf.square(rgb-prediction)\n",
        "  l2 = tf.reduce_sum(input_tensor=squares) / tf.reduce_sum(input_tensor=segmented)\n",
        "  return l2\n",
        "\n",
        "params = {}\n",
        "params['net_input_size'] = 512\n",
        "\n",
        "checkpoint_filepath = '/content/checkpoint'\n",
        "data_dir = '/content/filelist.txt'\n",
        "validation_dir = '/content/filelist.txt'\n",
        "#validation_dir = ''\n",
        "output_resolution = [378, 504]\n",
        "output_resolution = [384, 510]\n",
        "# output_resolution = [1512, 2016]\n",
        "fliplr=False\n",
        "flipud=False\n",
        "rotate=False\n",
        "random_crop=False\n",
        "shuffle=False\n",
        "batch_size = 1\n",
        "learning_rate = 1e-2\n",
        "\n",
        "net_input_size = params['net_input_size']\n",
        "\n",
        "train_samples = dp.ImageFilesDataPipeline(\n",
        "    data_dir,\n",
        "    shuffle=shuffle,\n",
        "    net_input_size=params['net_input_size'],\n",
        "    capacity=1,\n",
        "    min_after_dequeue = 4,\n",
        "    batch_size=batch_size,\n",
        "    fliplr=fliplr, flipud=flipud, rotate=rotate,\n",
        "    random_crop=random_crop,\n",
        "    custaugment=False,\n",
        "    exposuremult=False,\n",
        "    output_resolution=output_resolution,\n",
        "    keras = True,\n",
        "    repeat = True).samples\n",
        "\n",
        "validation_samples = None\n",
        "if validation_dir != '':\n",
        "  validation_samples = dp.ImageFilesDataPipeline(\n",
        "      validation_dir,\n",
        "      net_input_size=params['net_input_size'],\n",
        "      capacity=1,\n",
        "      batch_size=1,\n",
        "      fliplr=False,flipud=False, rotate=False,\n",
        "      random_crop=True,\n",
        "      exposuremult=False,\n",
        "      output_resolution=output_resolution,\n",
        "      keras = True,\n",
        "      repeat = False).samples\n",
        "\n",
        "\n",
        "opti=tf.keras.optimizers.Adam(learning_rate, use_ema=False, ema_momentum=0.1, weight_decay=0.001)\n",
        "#opti=tfa.optimizers.MovingAverage(opti, 0.99)\n",
        "model = models.SRBlade(params)\n",
        "#model = models.HDRNet(params)\n",
        "\n",
        "#model.run_eagerly = False\n",
        "#model = load_model('/content/hdrnet/train/out', compile=False)\n",
        "try:\n",
        "  model.load_weights(checkpoint_filepath)\n",
        "except:\n",
        "  print(\"Couldn't load weights from \",checkpoint_filepath)\n",
        "\n",
        "model.compile(optimizer=opti, loss=['mse', returnPrediction], metrics={'output_1':PSNR},\n",
        "  run_eagerly=False)\n",
        "# model.compile(optimizer=opti, loss=[l2_w, returnPrediction], metrics={'output_1':PSNR_w, 'output_2':return0},\n",
        "# run_eagerly=False)\n",
        "\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "#model_checkpoint_callback = tfa.callbacks.AverageModelCheckpoint(\n",
        "  update_weights=True,\n",
        "  filepath=checkpoint_filepath,\n",
        "  save_weights_only=True,\n",
        "  monitor= ('val_' if validation_dir != '' else '') + 'PSNR',\n",
        "  #monitor= 'output_1_PSNR',\n",
        "  mode='max',\n",
        "  verbose=1,\n",
        "  save_freq = 'epoch',\n",
        "  save_best_only=True)\n",
        "\n",
        "\n",
        "\n",
        "history = model.fit(train_samples, epochs=50, steps_per_epoch = 200//batch_size, callbacks=[model_checkpoint_callback],\n",
        "  validation_data = validation_samples, validation_freq = 1, verbose = 'auto')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wIShtZgraOMy",
        "outputId": "55679b10-f883-427e-8d0a-5ccbcb3a320b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/input/DIV2K_train_HR': No such file or directory\n",
            "/content/drive/MyDrive\n",
            "Tensor(\"strided_slice_1:0\", shape=(), dtype=string)\n",
            "Tensor(\"strided_slice_2:0\", shape=(), dtype=string)\n",
            "Tensor(\"Shape:0\", shape=(3,), dtype=int32)\n",
            "Tensor(\"Shape_1:0\", shape=(3,), dtype=int32)\n",
            "Tensor(\"strided_slice_1:0\", shape=(), dtype=string)\n",
            "Tensor(\"strided_slice_2:0\", shape=(), dtype=string)\n",
            "Tensor(\"Shape:0\", shape=(3,), dtype=int32)\n",
            "Tensor(\"Shape_1:0\", shape=(3,), dtype=int32)\n",
            "Couldn't load weights from  /content/checkpoint\n",
            "Epoch 1/50\n",
            "512\n",
            "Tensor(\"sr_blade_22/Shape_3:0\", shape=(4,), dtype=int32)\n",
            "Tensor(\"sr_blade_22/mul:0\", shape=(2,), dtype=int32)\n",
            "Tensor(\"sr_blade_22/Shape_6:0\", shape=(4,), dtype=int32)\n",
            "Tensor(\"sr_blade_22/mul:0\", shape=(2,), dtype=int32)\n",
            "Tensor(\"sr_blade_22/Shape_9:0\", shape=(4,), dtype=int32)\n",
            "Tensor(\"sr_blade_22/mul:0\", shape=(2,), dtype=int32)\n",
            "Tensor(\"sr_blade_22/Shape_12:0\", shape=(4,), dtype=int32)\n",
            "Tensor(\"sr_blade_22/mul:0\", shape=(2,), dtype=int32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['sr_blade_22/Dtr:0', 'sr_blade_22/Dth:0', 'sr_blade_22/kDetail:0', 'sr_blade_22/kDenoise:0', 'sr_blade_22/kStretch:0', 'sr_blade_22/kShrink:0', 'sr_blade_22/kDetail2:0', 'sr_blade_22/kDenoise2:0', 'sr_blade_22/kStretch2:0', 'sr_blade_22/kShrink2:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['sr_blade_22/Dtr:0', 'sr_blade_22/Dth:0', 'sr_blade_22/kDetail:0', 'sr_blade_22/kDenoise:0', 'sr_blade_22/kStretch:0', 'sr_blade_22/kShrink:0', 'sr_blade_22/kDetail2:0', 'sr_blade_22/kDenoise2:0', 'sr_blade_22/kStretch2:0', 'sr_blade_22/kShrink2:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "512\n",
            "Tensor(\"sr_blade_22/Shape_3:0\", shape=(4,), dtype=int32)\n",
            "Tensor(\"sr_blade_22/mul:0\", shape=(2,), dtype=int32)\n",
            "Tensor(\"sr_blade_22/Shape_6:0\", shape=(4,), dtype=int32)\n",
            "Tensor(\"sr_blade_22/mul:0\", shape=(2,), dtype=int32)\n",
            "Tensor(\"sr_blade_22/Shape_9:0\", shape=(4,), dtype=int32)\n",
            "Tensor(\"sr_blade_22/mul:0\", shape=(2,), dtype=int32)\n",
            "Tensor(\"sr_blade_22/Shape_12:0\", shape=(4,), dtype=int32)\n",
            "Tensor(\"sr_blade_22/mul:0\", shape=(2,), dtype=int32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['sr_blade_22/Dtr:0', 'sr_blade_22/Dth:0', 'sr_blade_22/kDetail:0', 'sr_blade_22/kDenoise:0', 'sr_blade_22/kStretch:0', 'sr_blade_22/kShrink:0', 'sr_blade_22/kDetail2:0', 'sr_blade_22/kDenoise2:0', 'sr_blade_22/kStretch2:0', 'sr_blade_22/kShrink2:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['sr_blade_22/Dtr:0', 'sr_blade_22/Dth:0', 'sr_blade_22/kDetail:0', 'sr_blade_22/kDenoise:0', 'sr_blade_22/kStretch:0', 'sr_blade_22/kShrink:0', 'sr_blade_22/kDetail2:0', 'sr_blade_22/kDenoise2:0', 'sr_blade_22/kStretch2:0', 'sr_blade_22/kShrink2:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200/200 [==============================] - ETA: 0s - loss: 1.0415 - PSNR: 15.9118512\n",
            "Tensor(\"sr_blade_22/Shape_3:0\", shape=(4,), dtype=int32)\n",
            "Tensor(\"sr_blade_22/mul:0\", shape=(2,), dtype=int32)\n",
            "Tensor(\"sr_blade_22/Shape_6:0\", shape=(4,), dtype=int32)\n",
            "Tensor(\"sr_blade_22/mul:0\", shape=(2,), dtype=int32)\n",
            "Tensor(\"sr_blade_22/Shape_9:0\", shape=(4,), dtype=int32)\n",
            "Tensor(\"sr_blade_22/mul:0\", shape=(2,), dtype=int32)\n",
            "Tensor(\"sr_blade_22/Shape_12:0\", shape=(4,), dtype=int32)\n",
            "Tensor(\"sr_blade_22/mul:0\", shape=(2,), dtype=int32)\n",
            "\n",
            "Epoch 1: val_PSNR improved from -inf to 23.59038, saving model to /content/checkpoint\n",
            "200/200 [==============================] - 102s 244ms/step - loss: 1.0415 - PSNR: 15.9118 - val_loss: 0.0044 - val_PSNR: 23.5904\n",
            "Epoch 2/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0036 - PSNR: 24.5027\n",
            "Epoch 2: val_PSNR improved from 23.59038 to 25.29967, saving model to /content/checkpoint\n",
            "200/200 [==============================] - 45s 226ms/step - loss: 0.0036 - PSNR: 24.5027 - val_loss: 0.0030 - val_PSNR: 25.2997\n",
            "Epoch 3/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0026 - PSNR: 25.9416\n",
            "Epoch 3: val_PSNR improved from 25.29967 to 26.52701, saving model to /content/checkpoint\n",
            "200/200 [==============================] - 47s 234ms/step - loss: 0.0026 - PSNR: 25.9416 - val_loss: 0.0022 - val_PSNR: 26.5270\n",
            "Epoch 4/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0020 - PSNR: 26.9922\n",
            "Epoch 4: val_PSNR improved from 26.52701 to 27.41094, saving model to /content/checkpoint\n",
            "200/200 [==============================] - 46s 229ms/step - loss: 0.0020 - PSNR: 26.9922 - val_loss: 0.0018 - val_PSNR: 27.4109\n",
            "Epoch 5/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0017 - PSNR: 27.7378\n",
            "Epoch 5: val_PSNR improved from 27.41094 to 28.03005, saving model to /content/checkpoint\n",
            "200/200 [==============================] - 46s 231ms/step - loss: 0.0017 - PSNR: 27.7378 - val_loss: 0.0016 - val_PSNR: 28.0300\n",
            "Epoch 6/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0015 - PSNR: 28.2559\n",
            "Epoch 6: val_PSNR improved from 28.03005 to 28.45712, saving model to /content/checkpoint\n",
            "200/200 [==============================] - 46s 232ms/step - loss: 0.0015 - PSNR: 28.2559 - val_loss: 0.0014 - val_PSNR: 28.4571\n",
            "Epoch 7/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0014 - PSNR: 28.6119\n",
            "Epoch 7: val_PSNR improved from 28.45712 to 28.74972, saving model to /content/checkpoint\n",
            "200/200 [==============================] - 45s 224ms/step - loss: 0.0014 - PSNR: 28.6119 - val_loss: 0.0013 - val_PSNR: 28.7497\n",
            "Epoch 8/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0013 - PSNR: 28.8564\n",
            "Epoch 8: val_PSNR improved from 28.74972 to 28.95200, saving model to /content/checkpoint\n",
            "200/200 [==============================] - 48s 240ms/step - loss: 0.0013 - PSNR: 28.8564 - val_loss: 0.0013 - val_PSNR: 28.9520\n",
            "Epoch 9/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0013 - PSNR: 29.0275\n",
            "Epoch 9: val_PSNR improved from 28.95200 to 29.09617, saving model to /content/checkpoint\n",
            "200/200 [==============================] - 44s 223ms/step - loss: 0.0013 - PSNR: 29.0275 - val_loss: 0.0012 - val_PSNR: 29.0962\n",
            "Epoch 10/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0012 - PSNR: 29.1522\n",
            "Epoch 10: val_PSNR improved from 29.09617 to 29.20412, saving model to /content/checkpoint\n",
            "200/200 [==============================] - 46s 232ms/step - loss: 0.0012 - PSNR: 29.1522 - val_loss: 0.0012 - val_PSNR: 29.2041\n",
            "Epoch 11/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0012 - PSNR: 29.2482\n",
            "Epoch 11: val_PSNR improved from 29.20412 to 29.28971, saving model to /content/checkpoint\n",
            "200/200 [==============================] - 47s 235ms/step - loss: 0.0012 - PSNR: 29.2482 - val_loss: 0.0012 - val_PSNR: 29.2897\n",
            "Epoch 12/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0012 - PSNR: 29.3263\n",
            "Epoch 12: val_PSNR improved from 29.28971 to 29.36134, saving model to /content/checkpoint\n",
            "200/200 [==============================] - 45s 225ms/step - loss: 0.0012 - PSNR: 29.3263 - val_loss: 0.0012 - val_PSNR: 29.3613\n",
            "Epoch 13/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0011 - PSNR: 29.3931\n",
            "Epoch 13: val_PSNR improved from 29.36134 to 29.42397, saving model to /content/checkpoint\n",
            "200/200 [==============================] - 46s 231ms/step - loss: 0.0011 - PSNR: 29.3931 - val_loss: 0.0011 - val_PSNR: 29.4240\n",
            "Epoch 14/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0011 - PSNR: 29.4526\n",
            "Epoch 14: val_PSNR improved from 29.42397 to 29.48062, saving model to /content/checkpoint\n",
            "200/200 [==============================] - 45s 223ms/step - loss: 0.0011 - PSNR: 29.4526 - val_loss: 0.0011 - val_PSNR: 29.4806\n",
            "Epoch 15/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0011 - PSNR: 29.5070\n",
            "Epoch 15: val_PSNR improved from 29.48062 to 29.53311, saving model to /content/checkpoint\n",
            "200/200 [==============================] - 47s 237ms/step - loss: 0.0011 - PSNR: 29.5070 - val_loss: 0.0011 - val_PSNR: 29.5331\n",
            "Epoch 16/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0011 - PSNR: 29.5579\n",
            "Epoch 16: val_PSNR improved from 29.53311 to 29.58240, saving model to /content/checkpoint\n",
            "200/200 [==============================] - 44s 222ms/step - loss: 0.0011 - PSNR: 29.5579 - val_loss: 0.0011 - val_PSNR: 29.5824\n",
            "Epoch 17/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0034 - PSNR: 27.9782\n",
            "Epoch 17: val_PSNR improved from 29.58240 to 29.60099, saving model to /content/checkpoint\n",
            "200/200 [==============================] - 47s 233ms/step - loss: 0.0034 - PSNR: 27.9782 - val_loss: 0.0011 - val_PSNR: 29.6010\n",
            "Epoch 18/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0011 - PSNR: 29.6288\n",
            "Epoch 18: val_PSNR improved from 29.60099 to 29.65508, saving model to /content/checkpoint\n",
            "200/200 [==============================] - 45s 226ms/step - loss: 0.0011 - PSNR: 29.6288 - val_loss: 0.0011 - val_PSNR: 29.6551\n",
            "Epoch 19/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0011 - PSNR: 29.6790\n",
            "Epoch 19: val_PSNR improved from 29.65508 to 29.70249, saving model to /content/checkpoint\n",
            "200/200 [==============================] - 46s 230ms/step - loss: 0.0011 - PSNR: 29.6790 - val_loss: 0.0011 - val_PSNR: 29.7025\n",
            "Epoch 20/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0027 - PSNR: 28.2914\n",
            "Epoch 20: val_PSNR did not improve from 29.70249\n",
            "200/200 [==============================] - 47s 233ms/step - loss: 0.0027 - PSNR: 28.2914 - val_loss: 0.0011 - val_PSNR: 29.6879\n",
            "Epoch 21/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0011 - PSNR: 29.7231\n",
            "Epoch 21: val_PSNR improved from 29.70249 to 29.71297, saving model to /content/checkpoint\n",
            "200/200 [==============================] - 45s 226ms/step - loss: 0.0011 - PSNR: 29.7231 - val_loss: 0.0011 - val_PSNR: 29.7130\n",
            "Epoch 22/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0023 - PSNR: 28.4830\n",
            "Epoch 22: val_PSNR improved from 29.71297 to 29.75793, saving model to /content/checkpoint\n",
            "200/200 [==============================] - 46s 230ms/step - loss: 0.0023 - PSNR: 28.4830 - val_loss: 0.0011 - val_PSNR: 29.7579\n",
            "Epoch 23/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0022 - PSNR: 28.5354\n",
            "Epoch 23: val_PSNR did not improve from 29.75793\n",
            "200/200 [==============================] - 45s 225ms/step - loss: 0.0022 - PSNR: 28.5354 - val_loss: 0.0011 - val_PSNR: 29.7478\n",
            "Epoch 24/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0030 - PSNR: 27.9530\n",
            "Epoch 24: val_PSNR did not improve from 29.75793\n",
            "200/200 [==============================] - 47s 232ms/step - loss: 0.0030 - PSNR: 27.9530 - val_loss: 0.0113 - val_PSNR: 19.4593\n",
            "Epoch 25/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0024 - PSNR: 28.1403\n",
            "Epoch 25: val_PSNR did not improve from 29.75793\n",
            "200/200 [==============================] - 44s 222ms/step - loss: 0.0024 - PSNR: 28.1403 - val_loss: 0.0024 - val_PSNR: 26.2163\n",
            "Epoch 26/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0028 - PSNR: 27.5792\n",
            "Epoch 26: val_PSNR did not improve from 29.75793\n",
            "200/200 [==============================] - 47s 233ms/step - loss: 0.0028 - PSNR: 27.5792 - val_loss: 0.0020 - val_PSNR: 26.8944\n",
            "Epoch 27/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0031 - PSNR: 27.3095\n",
            "Epoch 27: val_PSNR did not improve from 29.75793\n",
            "200/200 [==============================] - 47s 232ms/step - loss: 0.0031 - PSNR: 27.3095 - val_loss: 0.0011 - val_PSNR: 29.5983\n",
            "Epoch 28/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0029 - PSNR: 27.4347\n",
            "Epoch 28: val_PSNR improved from 29.75793 to 29.78119, saving model to /content/checkpoint\n",
            "200/200 [==============================] - 44s 222ms/step - loss: 0.0029 - PSNR: 27.4347 - val_loss: 0.0011 - val_PSNR: 29.7812\n",
            "Epoch 29/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0034 - PSNR: 26.7175\n",
            "Epoch 29: val_PSNR did not improve from 29.78119\n",
            "200/200 [==============================] - 46s 230ms/step - loss: 0.0034 - PSNR: 26.7175 - val_loss: 0.0024 - val_PSNR: 26.2144\n",
            "Epoch 30/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0025 - PSNR: 28.1538\n",
            "Epoch 30: val_PSNR did not improve from 29.78119\n",
            "200/200 [==============================] - 46s 230ms/step - loss: 0.0025 - PSNR: 28.1538 - val_loss: 0.0012 - val_PSNR: 29.0753\n",
            "Epoch 31/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0030 - PSNR: 27.1937\n",
            "Epoch 31: val_PSNR improved from 29.78119 to 29.85059, saving model to /content/checkpoint\n",
            "200/200 [==============================] - 46s 231ms/step - loss: 0.0030 - PSNR: 27.1937 - val_loss: 0.0010 - val_PSNR: 29.8506\n",
            "Epoch 32/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0038 - PSNR: 26.9455\n",
            "Epoch 32: val_PSNR did not improve from 29.85059\n",
            "200/200 [==============================] - 44s 222ms/step - loss: 0.0038 - PSNR: 26.9455 - val_loss: 0.0012 - val_PSNR: 29.1060\n",
            "Epoch 33/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0019 - PSNR: 28.6911\n",
            "Epoch 33: val_PSNR improved from 29.85059 to 29.92857, saving model to /content/checkpoint\n",
            "200/200 [==============================] - 46s 230ms/step - loss: 0.0019 - PSNR: 28.6911 - val_loss: 0.0010 - val_PSNR: 29.9286\n",
            "Epoch 34/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0037 - PSNR: 27.1573\n",
            "Epoch 34: val_PSNR did not improve from 29.92857\n",
            "200/200 [==============================] - 46s 229ms/step - loss: 0.0037 - PSNR: 27.1573 - val_loss: 0.0010 - val_PSNR: 29.8060\n",
            "Epoch 35/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0019 - PSNR: 28.8469\n",
            "Epoch 35: val_PSNR improved from 29.92857 to 29.96685, saving model to /content/checkpoint\n",
            "200/200 [==============================] - 46s 231ms/step - loss: 0.0019 - PSNR: 28.8469 - val_loss: 0.0010 - val_PSNR: 29.9668\n",
            "Epoch 36/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0043 - PSNR: 26.2803\n",
            "Epoch 36: val_PSNR did not improve from 29.96685\n",
            "200/200 [==============================] - 45s 223ms/step - loss: 0.0043 - PSNR: 26.2803 - val_loss: 0.0015 - val_PSNR: 28.1104\n",
            "Epoch 37/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0011 - PSNR: 29.7595\n",
            "Epoch 37: val_PSNR did not improve from 29.96685\n",
            "200/200 [==============================] - 46s 230ms/step - loss: 0.0011 - PSNR: 29.7595 - val_loss: 0.0019 - val_PSNR: 27.3004\n",
            "Epoch 38/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0043 - PSNR: 25.9343\n",
            "Epoch 38: val_PSNR improved from 29.96685 to 30.01122, saving model to /content/checkpoint\n",
            "200/200 [==============================] - 47s 234ms/step - loss: 0.0043 - PSNR: 25.9343 - val_loss: 9.9742e-04 - val_PSNR: 30.0112\n",
            "Epoch 39/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0019 - PSNR: 28.9332\n",
            "Epoch 39: val_PSNR did not improve from 30.01122\n",
            "200/200 [==============================] - 44s 222ms/step - loss: 0.0019 - PSNR: 28.9332 - val_loss: 0.0015 - val_PSNR: 28.3432\n",
            "Epoch 40/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0036 - PSNR: 27.1591\n",
            "Epoch 40: val_PSNR improved from 30.01122 to 30.03568, saving model to /content/checkpoint\n",
            "200/200 [==============================] - 48s 238ms/step - loss: 0.0036 - PSNR: 27.1591 - val_loss: 9.9182e-04 - val_PSNR: 30.0357\n",
            "Epoch 41/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.0037 - PSNR: 27.6882\n",
            "Epoch 41: val_PSNR did not improve from 30.03568\n",
            "200/200 [==============================] - 44s 223ms/step - loss: 0.0037 - PSNR: 27.6882 - val_loss: 0.0018 - val_PSNR: 27.3455\n",
            "Epoch 42/50\n",
            " 86/200 [===========>..................] - ETA: 26s - loss: 0.0030 - PSNR: 27.2810"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-a7244ee2f458>\u001b[0m in \u001b[0;36m<cell line: 153>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m history = model.fit(train_samples, epochs=50, steps_per_epoch = 200//batch_size, callbacks=[model_checkpoint_callback],\n\u001b[0m\u001b[1;32m    154\u001b[0m   validation_data = validation_samples, validation_freq = 1, verbose = 'auto')\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(model.Dtr)\n",
        "print(model.Dth)\n",
        "\n",
        "print(model.kDetail)\n",
        "print(model.kDenoise)\n",
        "print(model.kStretch)\n",
        "print(model.kShrink)\n",
        "\n",
        "print(model.kDetail2)\n",
        "print(model.kDenoise2)\n",
        "print(model.kStretch2)\n",
        "print(model.kShrink2)\n",
        "\n",
        "print(3000. * 1.525902E-05 * 0.860704768)\n",
        "print(100. * 1.525902E-05 * 0.860704768 / (3000. * 1.525902E-05 * 0.860704768))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xu3ZRJ04VY2a",
        "outputId": "7625eccc-bc5d-49f2-a468-9b67beb9269a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<superrestf.models2.SRBlade object at 0x7f2da558a5f0>\n",
            "<tf.Variable 'sr_blade_5/Dtr:0' shape=() dtype=float32, numpy=0.039400533>\n",
            "<tf.Variable 'sr_blade_5/Dth:0' shape=() dtype=float32, numpy=0.33333334>\n",
            "<tf.Variable 'sr_blade_5/kDetail:0' shape=() dtype=float32, numpy=0.27>\n",
            "<tf.Variable 'sr_blade_5/kDenoise:0' shape=() dtype=float32, numpy=0.55>\n",
            "<tf.Variable 'sr_blade_5/kStretch:0' shape=() dtype=float32, numpy=4.0>\n",
            "<tf.Variable 'sr_blade_5/kShrink:0' shape=() dtype=float32, numpy=1.0>\n",
            "<tf.Variable 'sr_blade_5/kDetail2:0' shape=() dtype=float32, numpy=0.54>\n",
            "<tf.Variable 'sr_blade_5/kDenoise2:0' shape=() dtype=float32, numpy=1.1>\n",
            "<tf.Variable 'sr_blade_5/kStretch2:0' shape=() dtype=float32, numpy=4.0>\n",
            "<tf.Variable 'sr_blade_5/kShrink2:0' shape=() dtype=float32, numpy=1.0>\n",
            "0.039400533807022076\n",
            "0.03333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_coords = np.arange(4)\n",
        "y_coords = np.arange(4)\n",
        "\n",
        "# Create a 2D NumPy array containing x and y indices\n",
        "indices = np.meshgrid(x_coords, y_coords)\n",
        "\n",
        "indices[0] = indices[0] % 2\n",
        "indices[1] = indices[1] % 2\n",
        "indices = indices[1] * 2 + indices[0]\n",
        "print(indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFQsNHmxiCvY",
        "outputId": "693ad20d-38e9-4ee9-cf6e-5f9a0b84a957"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 1 0 1]\n",
            " [2 3 2 3]\n",
            " [0 1 0 1]\n",
            " [2 3 2 3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ln -s /content/drive/MyDrive/superrestf/bladesr/test_images /content/input\n",
        "%cd /content/drive/MyDrive/superrestf/bin\n",
        "!python train2.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWdloDf7Gova",
        "outputId": "3c1c8ce8-e65d-4241-feb3-db6637429785"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}