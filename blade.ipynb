{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZoliN/colab/blob/main/blade.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJEFdQ_FgChu",
        "outputId": "71ee18c4-38dd-497a-f634-2c8a897aa885"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqsfE7V8DfvS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIKAVeuFGdJ7"
      },
      "outputs": [],
      "source": [
        "!unzip \"/content/drive/MyDrive/Colab Notebooks/zip.zip\" -d /content/\n",
        "%cd /content/zip\n",
        "!mkdir build\n",
        "%cd build\n",
        "!cmake .. -DCMAKE_BUILD_TYPE=Release"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKO7Gs9TazN6"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!wget  http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n",
        "!mkdir pics\n",
        "!unzip DIV2K_train_HR.zip -d pics/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qs-jiTJ9dtk5",
        "outputId": "caef592d-fdc6-4332-e033-c66d1f5761ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pics/DIV2K_train_HR\n"
          ]
        }
      ],
      "source": [
        "%cd /content/pics/DIV2K_train_HR\n",
        "!sh /content/drive/MyDrive/blade/copypics.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGU_PynQMCBJ"
      },
      "outputs": [],
      "source": [
        " %cd /content/zip/build\n",
        "!make -j4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVPCGRqEAB-K"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/drive/MyDrive/Colab Notebooks/2023_5_28_1_35_27.filter\"  /content/zip/filters/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0UONCsDbi04"
      },
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0UXLfCNOFyj",
        "outputId": "d73ab8f3-2f11-4c54-e7d2-3daf93f82b10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/zip/train_images\n"
          ]
        }
      ],
      "source": [
        "%cd /content/zip/train_images\n",
        "!mv *.png ./p/\n",
        "!mv ./p/08.png .\n",
        "!for i in {1..1000}; do cp 08.png \"test$i.png\"; done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWc4SrbPwJyB"
      },
      "outputs": [],
      "source": [
        "%cd /content/zip/\n",
        "!./build/blade\n",
        "!cp -r filters /content/drive/MyDrive/blade/\n",
        "!cp -r result_images /content/drive/MyDrive/blade/\n",
        "!cp temp_images/*.csv /content/drive/MyDrive/blade/\n",
        "while True:pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcweFQIsl_Sb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmzc68Ot5ra9"
      },
      "outputs": [],
      "source": [
        "!zip -r /content/drive/MyDrive/bladearch/src.zip /content/drive/MyDrive/blade/*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "!mkdir build\n",
        "%cd build\n",
        "!cmake /content/drive/MyDrive/superrestf/bladesr -DCMAKE_BUILD_TYPE=Release\n",
        "!pip install python_magic\n",
        "!apt-get install libmagic1"
      ],
      "metadata": {
        "id": "kUKzkXvvV7ZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " %cd /content/build\n",
        "!make -j4"
      ],
      "metadata": {
        "id": "rvKf-9a3WOxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs('/content/anal_images', exist_ok=True)\n",
        "!/content/build/blade\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "\n",
        "def iterate_files(directory):\n",
        "    for file in os.listdir(directory):\n",
        "        yield os.path.join(directory, file)\n",
        "\n",
        "inpath = '/content/anal_images'\n",
        "outpath = '/content/anal_tensors'\n",
        "os.makedirs(outpath, exist_ok=True)\n",
        "# Iterate over the files of the current directory\n",
        "for file in iterate_files(inpath):\n",
        "    filename = os.path.basename(file)\n",
        "    print(filename)\n",
        "    im_input = cv2.imread(file, -1)\n",
        "    print(im_input.shape)\n",
        "\n",
        "    byte_string = tf.io.serialize_tensor(im_input)\n",
        "    # Write the byte string to a file\n",
        "    with tf.io.gfile.GFile(outpath + '/' + filename[:-5] + '.bin', 'wb') as f:\n",
        "        f.write(byte_string.numpy())\n"
      ],
      "metadata": {
        "id": "q_XyDd3LWiJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "from importlib import reload\n",
        "\n",
        "scale = 2\n",
        "scalef = float(scale)\n",
        "invscale = 1./scalef\n",
        "\n",
        "img_raw = tf.io.read_file('/content/drive/MyDrive/superrestf/bladesr/test_images/12.png')\n",
        "im_input = tf.image.decode_image(img_raw)\n",
        "im_input = tf.cast(im_input, dtype=tf.float32)/255.0\n",
        "\n",
        "\n",
        "\n",
        "# img_raw = tf.io.read_file('/content/pic12.png')\n",
        "# im_input2 = tf.image.decode_image(img_raw, channels=1)\n",
        "# im_input2 = tf.cast(im_input2, dtype=tf.float32)/255.0\n",
        "# print('PSNR: ' + str(tf.image.psnr(im_input2[8:512-8,8:512-8,:], im_input[8:512-8,8:512-8,:], max_val=1.0).numpy()))\n",
        "\n",
        "orig_sz = tf.shape(im_input)[0:2]\n",
        "lr_sz = orig_sz // scale\n",
        "full_sz = lr_sz * scale\n",
        "\n",
        "\n",
        "analpath = '/content/anal_tensors'\n",
        "byte_string = []\n",
        "with tf.io.gfile.GFile(analpath + '/' + '12.png' + '.bin', 'rb') as f:\n",
        "    byte_string = f.read()\n",
        "\n",
        "# Deserialize the tensor from the byte string\n",
        "anal_tensor = tf.io.parse_tensor(byte_string, out_type=tf.float32)\n",
        "print(tf.shape(input=anal_tensor))\n",
        "\n",
        "lam1, lam2, c, s = tf.unstack(anal_tensor, axis=-1)\n",
        "\n",
        "Dtr = 3000. * 1.525902E-05 * 0.860704768\n",
        "Dth = 1000. * 1.525902E-05 * 0.860704768 * 1. / Dtr;\n",
        "kDetail = 0.5;\n",
        "kDenoise = 1.55;\n",
        "kStretch = 4.;\n",
        "kShrink = 1.;\n",
        "\n",
        "Dtr=0.0039259493\n",
        "Dth=0.33213648\n",
        "kDetail=0.6002224\n",
        "kDenoise=0.5469237\n",
        "kStretch=2.291745\n",
        "kShrink=2.3721561\n",
        "\n",
        "Dtr=0.48\n",
        "Dth=0.801\n",
        "kDetail=0.1388774\n",
        "kDenoise=0.272592\n",
        "kStretch=3.6042476\n",
        "kShrink=0.590034\n",
        "\n",
        "\n",
        "\n",
        "A = (lam1 - lam2) / (lam1 + lam2 + 0.0000000001);\n",
        "A = tf.clip_by_value(A, 0.1, 1.0);\n",
        "\n",
        "D = 1. - tf.sqrt(lam1) / Dtr + Dth\n",
        "D = tf.clip_by_value(D, 0.0, 1.0)\n",
        "\n",
        "k1h = kDetail * (kStretch * A +  (1. - A));\n",
        "k2h = kDetail / (kShrink * A +  (1. - A));\n",
        "\n",
        "k1 = ((1.0 - D)*k1h + D*kDenoise);\n",
        "k2 = ((1.0 - D)*k2h + D*kDenoise);\n",
        "k1 *= k1;\n",
        "k2 *= k2;\n",
        "\n",
        "x2 = c;\n",
        "y2 = s;\n",
        "x1 = s;\n",
        "y1 = -c;\n",
        "\n",
        "b11 = k1*x1*x1 + x2*x2*k2;\n",
        "b12 = k1*x1*y1 + x2*y2*k2;\n",
        "b22 = k1*y1*y1 + y2*y2*k2;\n",
        "\n",
        "det = b11*b22 - b12*b12 + 0.0000000001;\n",
        "\n",
        "m11 = b22 / det;\n",
        "m22 = b11 / det;\n",
        "m12 = -b12 / det;\n",
        "\n",
        "kerp = tf.stack((m11, m22, m12), axis = -1)\n",
        "kerp = tf.image.resize(kerp, full_sz, method='bilinear')\n",
        "m11, m22, m12 = tf.split(kerp, 3, axis = -1)\n",
        "\n",
        "\n",
        "######## k2\n",
        "# k1h = kDetail2 * (kStretch * A +  (1. - A));\n",
        "# k2h = kDetail2 / (kShrink * A +  (1. - A));\n",
        "\n",
        "# k1 = ((1.0 - D)*k1h + D*kDenoise2);\n",
        "# k2 = ((1.0 - D)*k2h + D*kDenoise2);\n",
        "# k1 *= k1;\n",
        "# k2 *= k2;\n",
        "\n",
        "# x2 = c;\n",
        "# y2 = s;\n",
        "# x1 = s;\n",
        "# y1 = -c;\n",
        "\n",
        "# b11 = k1*x1*x1 + x2*x2*k2;\n",
        "# b12 = k1*x1*y1 + x2*y2*k2;\n",
        "# b22 = k1*y1*y1 + y2*y2*k2;\n",
        "\n",
        "# det = b11*b22 - b12*b12 + 0.0000000001;\n",
        "\n",
        "# m11_2 = b22 / det;\n",
        "# m22_2 = b11 / det;\n",
        "# m12_2 = -b12 / det;\n",
        "\n",
        "# kerp = tf.stack((m11_2, m22_2, m12_2), axis = -1)\n",
        "# kerp = tf.image.resize(kerp, full_sz, method='bilinear')\n",
        "# m11_2, m22_2, m12_2 = tf.split(kerp, 3, axis = -1)\n",
        "\n",
        "\n",
        "im_lr = tf.image.resize(im_input, lr_sz, method='area')\n",
        "\n",
        "im_hr = tf.image.resize(im_lr, full_sz, method='nearest')\n",
        "\n",
        "cv2.imwrite('/content/im_hr.png', im_hr.numpy()*255.0)\n",
        "\n",
        "im_hr2 = tf.image.resize(im_lr, full_sz, method='lanczos3')\n",
        "cv2.imwrite('/content/im_hr2.png', im_hr2.numpy()*255.0)\n",
        "\n",
        "\n",
        "paddings = tf.constant([[2 * scale, 2 * scale], [2 * scale, 2 * scale], [0, 0]])\n",
        "# paddings = tf.constant([[2, 2], [2, 2], [0, 0]])\n",
        "im_padded = tf.pad(im_hr, paddings, \"SYMMETRIC\")\n",
        "\n",
        "#tf.convert_to_tensor(value, dtype=None\n",
        "im_dst = tf.fill(tf.concat( full_sz, tf.shape(im_lr)[2]), 0.0)\n",
        "\n",
        "im_dst = tf.fill(tf.shape(im_hr), 0.0)\n",
        "im_w = tf.fill(tf.shape(im_hr), 0.0)\n",
        "\n",
        "\n",
        "print(tf.shape(input=im_dst))\n",
        "print(tf.shape(input=im_padded))\n",
        "\n",
        "\n",
        "# Create two 1D arrays\n",
        "x_coords = np.arange(float(full_sz[0]))\n",
        "y_coords = np.arange(float(full_sz[1]))\n",
        "\n",
        "# Create a 2D NumPy array containing x and y indices\n",
        "indices = np.meshgrid(x_coords, y_coords)\n",
        "\n",
        "srcpos1 = np.stack([indices[0], indices[1]], 2)\n",
        "srcpos1 = (srcpos1 + 0.4995) * invscale\n",
        "srcpos = tf.convert_to_tensor(srcpos1, dtype=tf.float32)\n",
        "srcMidPos = tf.floor(srcpos) + 0.5;\n",
        "\n",
        "ls = 3.\n",
        "pi = 3.14159265\n",
        "for y in range(5):\n",
        "  ys = y * scale\n",
        "  y1 = float(y - 2)\n",
        "  for x in range(5):\n",
        "    xs = x * scale\n",
        "    x1 = float(x - 2)\n",
        "    posk = (srcMidPos + (x1, y1) - srcpos) * scalef\n",
        "    poskx, posky = tf.split(posk, 2, axis = -1)\n",
        "    #if (x==2 and y==2):\n",
        "    #  print(poskx.numpy()[0:4,0:4])\n",
        "    # kwx = tf.where(poskx == 0.0, 1.0, tf.where(poskx > ls, 0.0,  ls * tf.sin(pi * poskx) * tf.sin(pi * poskx / ls) / (pi * pi * poskx * poskx)))\n",
        "    # kwy = tf.where(posky == 0.0, 1.0, tf.where(posky > ls, 0.0,  ls * tf.sin(pi * posky) * tf.sin(pi * posky / ls) / (pi * pi * posky * posky)))\n",
        "    # kw = kwx * kwy\n",
        "\n",
        "    kw = tf.exp(-0.5 * ((poskx*m11+posky*m12)*poskx+(poskx*m12+posky*m22)*posky) )\n",
        "    # kw2 = tf.exp(-0.5 * ((poskx*m11_2+posky*m12_2)*poskx+(poskx*m12_2+posky*m22_2)*posky) )\n",
        "    # kw = kw1 * 2.0 - kw2 * 1.0\n",
        "    if (x==4 and y==2):\n",
        "      print(kw.numpy()[0:4,0:4])\n",
        "    im_w += kw\n",
        "    im_dst+= kw * im_padded[ys:ys+full_sz[0], xs: xs+full_sz[1]]\n",
        "\n",
        "halfRatio = invscale * 0.5\n",
        "\n",
        "# for y in range(5):\n",
        "#   y1 = float(y - 2)\n",
        "#   for x in range(5):\n",
        "#     x1 = float(x - 2)\n",
        "#     srcposc = srcpos + (x1 * invscale, y1 * invscale)\n",
        "#     comp = tf.where(tf.abs(srcposc - tf.floor(srcposc) - 0.5) < halfRatio, 1.0, 0.0)\n",
        "#     compx, compy = tf.split(comp, 2, axis = -1)\n",
        "#     kw = tf.where(compx * compx == 1.0, tf.exp(-0.5 * ((x1*m11+y1*m12)*x1+(x1*m12+y1*m22)*y1) ), 0.0)\n",
        "#     #if (x==3 and y==2):\n",
        "#     #  print(kw.numpy()[200:204,200:204])\n",
        "#     im_w += kw\n",
        "#     im_dst+= kw * im_padded[y:y+full_sz[0], x: x+full_sz[1]]\n",
        "\n",
        "\n",
        "im_dst = im_dst / (im_w + 0.0000001)\n",
        "\n",
        "cv2.imwrite('/content/out.png', im_dst.numpy()*255.0)\n",
        "\n",
        "cv2.imwrite('/content/test.jpg', A.numpy()*255.0)\n",
        "\n",
        "print(tf.shape(input=D))\n",
        "print('PSNR: ' + str(tf.image.psnr(im_dst, im_input, max_val=1.0).numpy()))\n",
        "print('PSNR upsampl: ' + str(tf.image.psnr(im_hr2, im_input, max_val=1.0).numpy()))\n",
        "\n",
        "\n",
        "\n",
        "checkpoint_filepath = '/content/checkpoint'\n",
        "\n",
        "model = models.SRBlade(params)\n",
        "try:\n",
        "  model.load_weights(checkpoint_filepath)\n",
        "except:\n",
        "  print(\"Couldn't load weights from \",checkpoint_filepath)\n",
        "\n",
        "model.params['net_input_size'] = tf.Variable(initial_value = 512, trainable=False, name= 'params_net_input_size')\n",
        "\n",
        "model.compile(loss=['mse', returnPrediction], metrics={'output_1':PSNR},\n",
        "  run_eagerly=True)\n",
        "\n",
        "outimg = model( {'image_input' : tf.expand_dims(im_lr,0), 'anal_input' : tf.expand_dims(anal_tensor,0)})\n",
        "\n",
        "print('PSNR mmodel: ' + str(tf.image.psnr(tf.squeeze(outimg,0), im_input, max_val=1.0).numpy()))\n",
        "cv2.imwrite('/content/outm.png', tf.squeeze(outimg,0).numpy()*255.0)\n",
        "\n"
      ],
      "metadata": {
        "id": "ZDssoEtqQQWh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "bfd819d6-8806-44b0-f9e1-70ad3c2c9ec3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PSNR: 30.554575\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "/content/anal_tensors/12.png.bin; No such file or directory",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-5d325f62e1cd>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mbyte_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'12.png'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.bin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mbyte_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Deserialize the tensor from the byte string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    114\u001b[0m       \u001b[0mstring\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mregular\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \"\"\"\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preread_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m       \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36m_preread_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m         raise errors.PermissionDeniedError(None, None,\n\u001b[1;32m     76\u001b[0m                                            \"File isn't open for reading\")\n\u001b[0;32m---> 77\u001b[0;31m       self._read_buf = _pywrap_file_io.BufferedInputStream(\n\u001b[0m\u001b[1;32m     78\u001b[0m           compat.path_to_str(self.__name), 1024 * 512)\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: /content/anal_tensors/12.png.bin; No such file or directory"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ykio78zrkina"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!ln -sf /content/drive/MyDrive/superrestf/bladesr/test_images /content/input\n",
        "!ln -sf /content/pics/DIV2K_train_HR /content/input\n",
        "!cp /content/drive/MyDrive/superrestf/bladesr/test_images/* /content/input/\n",
        "#!rm /content/checkpoint*\n",
        "%cd /content/drive/MyDrive/\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import skimage\n",
        "import skimage.io\n",
        "import logging\n",
        "from keras.models import load_model\n",
        "from tensorflow.python.ops.math_ops import truediv\n",
        "import tensorflow_probability as tfp\n",
        "#import tensorflow_addons as tfa\n",
        "\n",
        "\n",
        "import superrestf.models2 as models\n",
        "import superrestf.data_pipeline as dp\n",
        "\n",
        "from importlib import reload\n",
        "\n",
        "reload(models)\n",
        "reload(dp)\n",
        "\n",
        "\n",
        "numImgChs = 1\n",
        "\n",
        "logging.basicConfig(format=\"[%(process)d] %(levelname)s %(filename)s:%(lineno)s | %(message)s\")\n",
        "log = logging.getLogger(\"train\")\n",
        "log.setLevel(logging.INFO)\n",
        "\n",
        "def PSNR(im1, im2):\n",
        "  return tf.image.psnr(im1, im2, max_val=1.0)\n",
        "\n",
        "def returnPrediction(target, pred):\n",
        "  return pred\n",
        "\n",
        "def return0(target, pred):\n",
        "  return 0\n",
        "\n",
        "\n",
        "def l2_lossHist(target, prediction):\n",
        "  loss = tf.reduce_mean(input_tensor=tf.square(target-prediction))\n",
        "\n",
        "  percs = np.linspace(1, 100, 64, endpoint=False, dtype=np.float32)\n",
        "  hist1 = tfp.stats.percentile(target, percs, [1,2,3])\n",
        "  hist2 = tfp.stats.percentile(prediction, percs, [1,2,3])\n",
        "  histdiff2 = tf.reduce_mean(input_tensor=tf.square(hist1-hist2))\n",
        "  return loss + histdiff2 * 10.\n",
        "\n",
        "def PSNR_w(target, prediction):\n",
        "  rgb, segmented = tf.split(target, [numImgChs,1], 3)\n",
        "  squares = segmented * tf.square(rgb-prediction)\n",
        "  squares = tf.reshape(squares, [tf.shape(input=squares)[0], -1])\n",
        "  p = (-10/np.log(10))*tf.math.log(tf.reduce_sum(input_tensor=squares, axis=[1])\n",
        "          / tf.reduce_sum(input_tensor=segmented, axis=[1,2,3]))\n",
        "  return p\n",
        "\n",
        "\n",
        "def l2_w(target, prediction):\n",
        "  rgb, segmented = tf.split(target, [numImgChs,1], 3)\n",
        "  squares = segmented * tf.square(rgb-prediction)\n",
        "  l2 = tf.reduce_sum(input_tensor=squares) / tf.reduce_sum(input_tensor=segmented)\n",
        "  return l2\n",
        "\n",
        "params = {}\n",
        "params['net_input_size'] = 256\n",
        "\n",
        "checkpoint_filepath = '/content/checkpoint'\n",
        "data_dir = '/content/filelist.txt'\n",
        "validation_dir = '/content/filelistv.txt'\n",
        "#validation_dir = ''\n",
        "output_resolution = [378, 504]\n",
        "output_resolution = [384, 510]\n",
        "# output_resolution = [1512, 2016]\n",
        "fliplr=True\n",
        "flipud=True\n",
        "rotate=False\n",
        "random_crop=True\n",
        "shuffle=False\n",
        "batch_size = 128\n",
        "learning_rate = 1e-3\n",
        "\n",
        "net_input_size = params['net_input_size']\n",
        "\n",
        "train_samples = dp.ImageFilesDataPipeline(\n",
        "    data_dir,\n",
        "    shuffle=shuffle,\n",
        "    net_input_size=params['net_input_size'],\n",
        "    capacity=1,\n",
        "    min_after_dequeue = 4,\n",
        "    batch_size=batch_size,\n",
        "    fliplr=fliplr, flipud=flipud, rotate=rotate,\n",
        "    random_crop=random_crop,\n",
        "    custaugment=False,\n",
        "    exposuremult=False,\n",
        "    output_resolution=output_resolution,\n",
        "    keras = True,\n",
        "    repeat = True).samples\n",
        "\n",
        "validation_samples = None\n",
        "if validation_dir != '':\n",
        "  validation_samples = dp.ImageFilesDataPipeline(\n",
        "      validation_dir,\n",
        "      net_input_size=params['net_input_size'],\n",
        "      capacity=1,\n",
        "      batch_size=1,\n",
        "      fliplr=False,flipud=False, rotate=False,\n",
        "      random_crop=True,\n",
        "      exposuremult=False,\n",
        "      output_resolution=output_resolution,\n",
        "      keras = True,\n",
        "      repeat = False).samples\n",
        "\n",
        "\n",
        "opti=tf.keras.optimizers.Adam(learning_rate, use_ema=False, ema_momentum=0.1, weight_decay=0.001)\n",
        "#opti=tfa.optimizers.MovingAverage(opti, 0.99)\n",
        "model = models.SRBlade(params)\n",
        "#model = models.HDRNet(params)\n",
        "\n",
        "#model.run_eagerly = False\n",
        "#model = load_model('/content/hdrnet/train/out', compile=False)\n",
        "try:\n",
        "  model.load_weights(checkpoint_filepath)\n",
        "except:\n",
        "  print(\"Couldn't load weights from \",checkpoint_filepath)\n",
        "\n",
        "model.compile(optimizer=opti, loss=['mse', returnPrediction], metrics={'output_1':PSNR},\n",
        "  run_eagerly=False)\n",
        "# model.compile(optimizer=opti, loss=[l2_w, returnPrediction], metrics={'output_1':PSNR_w, 'output_2':return0},\n",
        "# run_eagerly=False)\n",
        "\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "#model_checkpoint_callback = tfa.callbacks.AverageModelCheckpoint(\n",
        "  update_weights=True,\n",
        "  filepath=checkpoint_filepath,\n",
        "  save_weights_only=True,\n",
        "  monitor= ('val_' if validation_dir != '' else '') + 'PSNR',\n",
        "  #monitor= 'output_1_PSNR',\n",
        "  mode='max',\n",
        "  verbose=1,\n",
        "  save_freq = 'epoch',\n",
        "  save_best_only=True)\n",
        "\n",
        "\n",
        "\n",
        "history = model.fit(train_samples, epochs=50, steps_per_epoch = 200//batch_size, callbacks=[model_checkpoint_callback],\n",
        "  validation_data = validation_samples, validation_freq = 1, verbose = 'auto')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wIShtZgraOMy",
        "outputId": "6492efac-28a4-49fb-cd63-df1d14104a3f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: -r not specified; omitting directory '/content/drive/MyDrive/superrestf/bladesr/test_images/t'\n",
            "cp: -r not specified; omitting directory '/content/drive/MyDrive/superrestf/bladesr/test_images/t2'\n",
            "cp: -r not specified; omitting directory '/content/drive/MyDrive/superrestf/bladesr/test_images/test_images'\n",
            "/content/drive/MyDrive\n",
            "Tensor(\"strided_slice_1:0\", shape=(), dtype=string)\n",
            "Tensor(\"strided_slice_2:0\", shape=(), dtype=string)\n",
            "Tensor(\"Shape:0\", shape=(3,), dtype=int32)\n",
            "Tensor(\"Shape_1:0\", shape=(3,), dtype=int32)\n",
            "Tensor(\"strided_slice_1:0\", shape=(), dtype=string)\n",
            "Tensor(\"strided_slice_2:0\", shape=(), dtype=string)\n",
            "Tensor(\"Shape:0\", shape=(3,), dtype=int32)\n",
            "Tensor(\"Shape_1:0\", shape=(3,), dtype=int32)\n",
            "Epoch 1/50\n",
            "Tensor(\"sr_blade_4/Shape_1:0\", shape=(4,), dtype=int32, device=/device:GPU:0)\n",
            "Tensor(\"sr_blade_4/mul:0\", shape=(2,), dtype=int32, device=/device:GPU:0)\n",
            "Tensor(\"sr_blade_4/Shape_2:0\", shape=(4,), dtype=int32, device=/device:GPU:0)\n",
            "Tensor(\"sr_blade_4/mul:0\", shape=(2,), dtype=int32, device=/device:GPU:0)\n",
            "Tensor(\"sr_blade_4/Shape_3:0\", shape=(4,), dtype=int32, device=/device:GPU:0)\n",
            "Tensor(\"sr_blade_4/mul:0\", shape=(2,), dtype=int32, device=/device:GPU:0)\n",
            "Tensor(\"sr_blade_4/Shape_4:0\", shape=(4,), dtype=int32, device=/device:GPU:0)\n",
            "Tensor(\"sr_blade_4/mul:0\", shape=(2,), dtype=int32, device=/device:GPU:0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['sr_blade_4/Dtr:0', 'sr_blade_4/Dth:0', 'sr_blade_4/kDetail:0', 'sr_blade_4/kDenoise:0', 'sr_blade_4/kStretch:0', 'sr_blade_4/kShrink:0', 'sr_blade_4/kDetail2:0', 'sr_blade_4/kDenoise2:0', 'sr_blade_4/kStretch2:0', 'sr_blade_4/kShrink2:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['sr_blade_4/Dtr:0', 'sr_blade_4/Dth:0', 'sr_blade_4/kDetail:0', 'sr_blade_4/kDenoise:0', 'sr_blade_4/kStretch:0', 'sr_blade_4/kShrink:0', 'sr_blade_4/kDetail2:0', 'sr_blade_4/kDenoise2:0', 'sr_blade_4/kStretch2:0', 'sr_blade_4/kShrink2:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"sr_blade_4/Shape_1:0\", shape=(4,), dtype=int32, device=/device:GPU:0)\n",
            "Tensor(\"sr_blade_4/mul:0\", shape=(2,), dtype=int32, device=/device:GPU:0)\n",
            "Tensor(\"sr_blade_4/Shape_2:0\", shape=(4,), dtype=int32, device=/device:GPU:0)\n",
            "Tensor(\"sr_blade_4/mul:0\", shape=(2,), dtype=int32, device=/device:GPU:0)\n",
            "Tensor(\"sr_blade_4/Shape_3:0\", shape=(4,), dtype=int32, device=/device:GPU:0)\n",
            "Tensor(\"sr_blade_4/mul:0\", shape=(2,), dtype=int32, device=/device:GPU:0)\n",
            "Tensor(\"sr_blade_4/Shape_4:0\", shape=(4,), dtype=int32, device=/device:GPU:0)\n",
            "Tensor(\"sr_blade_4/mul:0\", shape=(2,), dtype=int32, device=/device:GPU:0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['sr_blade_4/Dtr:0', 'sr_blade_4/Dth:0', 'sr_blade_4/kDetail:0', 'sr_blade_4/kDenoise:0', 'sr_blade_4/kStretch:0', 'sr_blade_4/kShrink:0', 'sr_blade_4/kDetail2:0', 'sr_blade_4/kDenoise2:0', 'sr_blade_4/kStretch2:0', 'sr_blade_4/kShrink2:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['sr_blade_4/Dtr:0', 'sr_blade_4/Dth:0', 'sr_blade_4/kDetail:0', 'sr_blade_4/kDenoise:0', 'sr_blade_4/kStretch:0', 'sr_blade_4/kShrink:0', 'sr_blade_4/kDetail2:0', 'sr_blade_4/kDenoise2:0', 'sr_blade_4/kStretch2:0', 'sr_blade_4/kShrink2:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/1 [==============================] - ETA: 0s - loss: 0.0012 - PSNR: 34.2573Tensor(\"sr_blade_4/Shape_1:0\", shape=(4,), dtype=int32, device=/device:GPU:0)\n",
            "Tensor(\"sr_blade_4/mul:0\", shape=(2,), dtype=int32, device=/device:GPU:0)\n",
            "Tensor(\"sr_blade_4/Shape_2:0\", shape=(4,), dtype=int32, device=/device:GPU:0)\n",
            "Tensor(\"sr_blade_4/mul:0\", shape=(2,), dtype=int32, device=/device:GPU:0)\n",
            "Tensor(\"sr_blade_4/Shape_3:0\", shape=(4,), dtype=int32, device=/device:GPU:0)\n",
            "Tensor(\"sr_blade_4/mul:0\", shape=(2,), dtype=int32, device=/device:GPU:0)\n",
            "Tensor(\"sr_blade_4/Shape_4:0\", shape=(4,), dtype=int32, device=/device:GPU:0)\n",
            "Tensor(\"sr_blade_4/mul:0\", shape=(2,), dtype=int32, device=/device:GPU:0)\n",
            "\n",
            "Epoch 1: val_PSNR improved from -inf to 31.42937, saving model to /content/checkpoint\n",
            "1/1 [==============================] - 51s 51s/step - loss: 0.0012 - PSNR: 34.2573 - val_loss: 7.1955e-04 - val_PSNR: 31.4294\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0013 - PSNR: 34.0497\n",
            "Epoch 2: val_PSNR did not improve from 31.42937\n",
            "1/1 [==============================] - 17s 17s/step - loss: 0.0013 - PSNR: 34.0497 - val_loss: 0.0010 - val_PSNR: 29.8625\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0013 - PSNR: 33.5158\n",
            "Epoch 3: val_PSNR did not improve from 31.42937\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.0013 - PSNR: 33.5158 - val_loss: 7.5584e-04 - val_PSNR: 31.2157\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 9.7790e-04 - PSNR: 34.3622\n",
            "Epoch 4: val_PSNR did not improve from 31.42937\n",
            "1/1 [==============================] - 22s 22s/step - loss: 9.7790e-04 - PSNR: 34.3622 - val_loss: 9.9054e-04 - val_PSNR: 30.0413\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0013 - PSNR: 34.0479\n",
            "Epoch 5: val_PSNR did not improve from 31.42937\n",
            "1/1 [==============================] - 21s 21s/step - loss: 0.0013 - PSNR: 34.0479 - val_loss: 0.0014 - val_PSNR: 28.5883\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0012 - PSNR: 34.0778\n",
            "Epoch 6: val_PSNR did not improve from 31.42937\n",
            "1/1 [==============================] - 19s 19s/step - loss: 0.0012 - PSNR: 34.0778 - val_loss: 9.5689e-04 - val_PSNR: 30.1914\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 9.9272e-04 - PSNR: 33.4312\n",
            "Epoch 7: val_PSNR did not improve from 31.42937\n",
            "1/1 [==============================] - 23s 23s/step - loss: 9.9272e-04 - PSNR: 33.4312 - val_loss: 9.4991e-04 - val_PSNR: 30.2232\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0015 - PSNR: 33.1431\n",
            "Epoch 8: val_PSNR did not improve from 31.42937\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.0015 - PSNR: 33.1431 - val_loss: 0.0016 - val_PSNR: 28.0905\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0012 - PSNR: 33.7339\n",
            "Epoch 9: val_PSNR did not improve from 31.42937\n",
            "1/1 [==============================] - 21s 21s/step - loss: 0.0012 - PSNR: 33.7339 - val_loss: 9.4818e-04 - val_PSNR: 30.2311\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0010 - PSNR: 34.1357\n",
            "Epoch 10: val_PSNR did not improve from 31.42937\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0010 - PSNR: 34.1357 - val_loss: 8.2687e-04 - val_PSNR: 30.8256\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0013 - PSNR: 33.6284\n",
            "Epoch 11: val_PSNR did not improve from 31.42937\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.0013 - PSNR: 33.6284 - val_loss: 0.0010 - val_PSNR: 29.9333\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0013 - PSNR: 33.5955\n",
            "Epoch 12: val_PSNR did not improve from 31.42937\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.0013 - PSNR: 33.5955 - val_loss: 0.0010 - val_PSNR: 29.9039\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0012 - PSNR: 34.3661\n",
            "Epoch 13: val_PSNR did not improve from 31.42937\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0012 - PSNR: 34.3661 - val_loss: 0.0013 - val_PSNR: 28.7664\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0012 - PSNR: 33.3228\n",
            "Epoch 14: val_PSNR improved from 31.42937 to 31.59208, saving model to /content/checkpoint\n",
            "1/1 [==============================] - 21s 21s/step - loss: 0.0012 - PSNR: 33.3228 - val_loss: 6.9309e-04 - val_PSNR: 31.5921\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 9.7895e-04 - PSNR: 34.0973\n",
            "Epoch 15: val_PSNR did not improve from 31.59208\n",
            "1/1 [==============================] - 19s 19s/step - loss: 9.7895e-04 - PSNR: 34.0973 - val_loss: 0.0010 - val_PSNR: 29.8822\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0011 - PSNR: 33.6512\n",
            "Epoch 16: val_PSNR did not improve from 31.59208\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0011 - PSNR: 33.6512 - val_loss: 7.0385e-04 - val_PSNR: 31.5252\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0014 - PSNR: 33.7701\n",
            "Epoch 17: val_PSNR did not improve from 31.59208\n",
            "1/1 [==============================] - 19s 19s/step - loss: 0.0014 - PSNR: 33.7701 - val_loss: 0.0010 - val_PSNR: 29.8452\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0013 - PSNR: 33.8058\n",
            "Epoch 18: val_PSNR did not improve from 31.59208\n",
            "1/1 [==============================] - 21s 21s/step - loss: 0.0013 - PSNR: 33.8058 - val_loss: 0.0010 - val_PSNR: 29.9550\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0011 - PSNR: 33.5057\n",
            "Epoch 19: val_PSNR did not improve from 31.59208\n",
            "1/1 [==============================] - 21s 21s/step - loss: 0.0011 - PSNR: 33.5057 - val_loss: 9.9720e-04 - val_PSNR: 30.0122\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0013 - PSNR: 33.6457\n",
            "Epoch 20: val_PSNR did not improve from 31.59208\n",
            "1/1 [==============================] - 21s 21s/step - loss: 0.0013 - PSNR: 33.6457 - val_loss: 0.0014 - val_PSNR: 28.6434\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0012 - PSNR: 33.6375\n",
            "Epoch 21: val_PSNR did not improve from 31.59208\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.0012 - PSNR: 33.6375 - val_loss: 0.0015 - val_PSNR: 28.2181\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0011 - PSNR: 34.4723\n",
            "Epoch 22: val_PSNR did not improve from 31.59208\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0011 - PSNR: 34.4723 - val_loss: 8.8141e-04 - val_PSNR: 30.5482\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0017 - PSNR: 32.6533\n",
            "Epoch 23: val_PSNR did not improve from 31.59208\n",
            "1/1 [==============================] - 21s 21s/step - loss: 0.0017 - PSNR: 32.6533 - val_loss: 9.9241e-04 - val_PSNR: 30.0331\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0013 - PSNR: 34.2884\n",
            "Epoch 24: val_PSNR improved from 31.59208 to 31.94690, saving model to /content/checkpoint\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.0013 - PSNR: 34.2884 - val_loss: 6.3872e-04 - val_PSNR: 31.9469\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0012 - PSNR: 33.5267\n",
            "Epoch 25: val_PSNR did not improve from 31.94690\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0012 - PSNR: 33.5267 - val_loss: 0.0010 - val_PSNR: 29.8136\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0016 - PSNR: 32.7982\n",
            "Epoch 26: val_PSNR did not improve from 31.94690\n",
            "1/1 [==============================] - 19s 19s/step - loss: 0.0016 - PSNR: 32.7982 - val_loss: 0.0015 - val_PSNR: 28.2655\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0012 - PSNR: 34.2081\n",
            "Epoch 27: val_PSNR did not improve from 31.94690\n",
            "1/1 [==============================] - 21s 21s/step - loss: 0.0012 - PSNR: 34.2081 - val_loss: 0.0011 - val_PSNR: 29.7522\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 9.3052e-04 - PSNR: 34.5917\n",
            "Epoch 28: val_PSNR did not improve from 31.94690\n",
            "1/1 [==============================] - 22s 22s/step - loss: 9.3052e-04 - PSNR: 34.5917 - val_loss: 9.0484e-04 - val_PSNR: 30.4343\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0015 - PSNR: 33.7459\n",
            "Epoch 29: val_PSNR did not improve from 31.94690\n",
            "1/1 [==============================] - 21s 21s/step - loss: 0.0015 - PSNR: 33.7459 - val_loss: 7.9535e-04 - val_PSNR: 30.9944\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0015 - PSNR: 33.2105\n",
            "Epoch 30: val_PSNR did not improve from 31.94690\n",
            "1/1 [==============================] - 19s 19s/step - loss: 0.0015 - PSNR: 33.2105 - val_loss: 7.2866e-04 - val_PSNR: 31.3747\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0012 - PSNR: 33.5113\n",
            "Epoch 31: val_PSNR did not improve from 31.94690\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0012 - PSNR: 33.5113 - val_loss: 0.0011 - val_PSNR: 29.7654\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0012 - PSNR: 34.1535\n",
            "Epoch 32: val_PSNR did not improve from 31.94690\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.0012 - PSNR: 34.1535 - val_loss: 8.7050e-04 - val_PSNR: 30.6023\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0012 - PSNR: 33.9002\n",
            "Epoch 33: val_PSNR did not improve from 31.94690\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.0012 - PSNR: 33.9002 - val_loss: 9.0735e-04 - val_PSNR: 30.4223\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0015 - PSNR: 33.2482\n",
            "Epoch 34: val_PSNR did not improve from 31.94690\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0015 - PSNR: 33.2482 - val_loss: 7.7927e-04 - val_PSNR: 31.0831\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0015 - PSNR: 32.9265\n",
            "Epoch 35: val_PSNR did not improve from 31.94690\n",
            "1/1 [==============================] - 19s 19s/step - loss: 0.0015 - PSNR: 32.9265 - val_loss: 6.7527e-04 - val_PSNR: 31.7052\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0014 - PSNR: 32.8406\n",
            "Epoch 36: val_PSNR did not improve from 31.94690\n",
            "1/1 [==============================] - 21s 21s/step - loss: 0.0014 - PSNR: 32.8406 - val_loss: 0.0014 - val_PSNR: 28.5146\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0011 - PSNR: 33.9995\n",
            "Epoch 37: val_PSNR did not improve from 31.94690\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0011 - PSNR: 33.9995 - val_loss: 0.0013 - val_PSNR: 28.9814\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0015 - PSNR: 33.3859\n",
            "Epoch 38: val_PSNR did not improve from 31.94690\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.0015 - PSNR: 33.3859 - val_loss: 8.2185e-04 - val_PSNR: 30.8521\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0013 - PSNR: 33.6583\n",
            "Epoch 39: val_PSNR did not improve from 31.94690\n",
            "1/1 [==============================] - 19s 19s/step - loss: 0.0013 - PSNR: 33.6583 - val_loss: 0.0011 - val_PSNR: 29.7352\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0011 - PSNR: 33.7492\n",
            "Epoch 40: val_PSNR did not improve from 31.94690\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0011 - PSNR: 33.7492 - val_loss: 8.0267e-04 - val_PSNR: 30.9546\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0016 - PSNR: 33.5640\n",
            "Epoch 41: val_PSNR did not improve from 31.94690\n",
            "1/1 [==============================] - 19s 19s/step - loss: 0.0016 - PSNR: 33.5640 - val_loss: 7.1314e-04 - val_PSNR: 31.4683\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0013 - PSNR: 34.0806\n",
            "Epoch 42: val_PSNR did not improve from 31.94690\n",
            "1/1 [==============================] - 21s 21s/step - loss: 0.0013 - PSNR: 34.0806 - val_loss: 0.0012 - val_PSNR: 29.2567\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0012 - PSNR: 33.2560\n",
            "Epoch 43: val_PSNR did not improve from 31.94690\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0012 - PSNR: 33.2560 - val_loss: 0.0011 - val_PSNR: 29.7433\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0013 - PSNR: 34.2887\n",
            "Epoch 44: val_PSNR did not improve from 31.94690\n",
            "1/1 [==============================] - 19s 19s/step - loss: 0.0013 - PSNR: 34.2887 - val_loss: 7.2065e-04 - val_PSNR: 31.4228\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0014 - PSNR: 33.2782\n",
            "Epoch 45: val_PSNR did not improve from 31.94690\n",
            "1/1 [==============================] - 21s 21s/step - loss: 0.0014 - PSNR: 33.2782 - val_loss: 0.0011 - val_PSNR: 29.4022\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0010 - PSNR: 34.5204\n",
            "Epoch 46: val_PSNR did not improve from 31.94690\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0010 - PSNR: 34.5204 - val_loss: 0.0014 - val_PSNR: 28.5095\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0014 - PSNR: 33.9294\n",
            "Epoch 47: val_PSNR did not improve from 31.94690\n",
            "1/1 [==============================] - 21s 21s/step - loss: 0.0014 - PSNR: 33.9294 - val_loss: 8.0763e-04 - val_PSNR: 30.9279\n",
            "Epoch 48/50\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-c3bbed9b1e13>\u001b[0m in \u001b[0;36m<cell line: 151>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m history = model.fit(train_samples, epochs=50, steps_per_epoch = 200//batch_size, callbacks=[model_checkpoint_callback],\n\u001b[0m\u001b[1;32m    152\u001b[0m   validation_data = validation_samples, validation_freq = 1, verbose = 'auto')\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(model.Dtr)\n",
        "print(model.Dth)\n",
        "\n",
        "print(model.kDetail)\n",
        "print(model.kDenoise)\n",
        "print(model.kStretch)\n",
        "print(model.kShrink)\n",
        "\n",
        "print(model.kDetail2)\n",
        "print(model.kDenoise2)\n",
        "print(model.kStretch2)\n",
        "print(model.kShrink2)\n",
        "\n",
        "print(3000. * 1.525902E-05 * 0.860704768)\n",
        "print(100. * 1.525902E-05 * 0.860704768 / (3000. * 1.525902E-05 * 0.860704768))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xu3ZRJ04VY2a",
        "outputId": "7625eccc-bc5d-49f2-a468-9b67beb9269a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<superrestf.models2.SRBlade object at 0x7f2da558a5f0>\n",
            "<tf.Variable 'sr_blade_5/Dtr:0' shape=() dtype=float32, numpy=0.039400533>\n",
            "<tf.Variable 'sr_blade_5/Dth:0' shape=() dtype=float32, numpy=0.33333334>\n",
            "<tf.Variable 'sr_blade_5/kDetail:0' shape=() dtype=float32, numpy=0.27>\n",
            "<tf.Variable 'sr_blade_5/kDenoise:0' shape=() dtype=float32, numpy=0.55>\n",
            "<tf.Variable 'sr_blade_5/kStretch:0' shape=() dtype=float32, numpy=4.0>\n",
            "<tf.Variable 'sr_blade_5/kShrink:0' shape=() dtype=float32, numpy=1.0>\n",
            "<tf.Variable 'sr_blade_5/kDetail2:0' shape=() dtype=float32, numpy=0.54>\n",
            "<tf.Variable 'sr_blade_5/kDenoise2:0' shape=() dtype=float32, numpy=1.1>\n",
            "<tf.Variable 'sr_blade_5/kStretch2:0' shape=() dtype=float32, numpy=4.0>\n",
            "<tf.Variable 'sr_blade_5/kShrink2:0' shape=() dtype=float32, numpy=1.0>\n",
            "0.039400533807022076\n",
            "0.03333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_coords = np.arange(4)\n",
        "y_coords = np.arange(4)\n",
        "\n",
        "# Create a 2D NumPy array containing x and y indices\n",
        "indices = np.meshgrid(x_coords, y_coords)\n",
        "\n",
        "indices[0] = indices[0] % 2\n",
        "indices[1] = indices[1] % 2\n",
        "indices = indices[1] * 2 + indices[0]\n",
        "print(indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFQsNHmxiCvY",
        "outputId": "693ad20d-38e9-4ee9-cf6e-5f9a0b84a957"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 1 0 1]\n",
            " [2 3 2 3]\n",
            " [0 1 0 1]\n",
            " [2 3 2 3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ln -s /content/drive/MyDrive/superrestf/bladesr/test_images /content/input\n",
        "%cd /content/drive/MyDrive/superrestf/bin\n",
        "!python train2.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWdloDf7Gova",
        "outputId": "3c1c8ce8-e65d-4241-feb3-db6637429785"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}